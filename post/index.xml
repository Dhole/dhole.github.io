<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dhole&#39;s blog</title>
    <link>https://dhole.github.io/post/</link>
    <description>Recent content in Posts on Dhole&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Nov 2016 01:17:17 -0700</lastBuildDate>
    <atom:link href="https://dhole.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>rdiff-backup-1.2.8 in Alpine</title>
      <link>https://dhole.github.io/post/rdiff-backup-alpine/</link>
      <pubDate>Tue, 01 Nov 2016 01:17:17 -0700</pubDate>
      
      <guid>https://dhole.github.io/post/rdiff-backup-alpine/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;A few days ago I wanted to start doing incremental backups from my laptop to my
Raspberry Pi 2 running Alpine Linux.  I&amp;rsquo;ve had used rdiff-backup for some years
now and I&amp;rsquo;m really happy with it.  rdiff-backup is similar to rsync, in the
sense that lets you synchronize folders over the network, but it has two added
nice features: when synchronizing, only the differences between the files that
have changed are sent; and after every synchronization, the differences between
the old version of the files and the new ones is kept.  In other words, it keeps
backwards in time incremental backups, allowing you to revert the files in time.&lt;/p&gt;

&lt;p&gt;After trying to backup my Documents folder from my Debian laptop I encountered
an error that was caused by an incompatibility between versions.  &lt;a href=&#34;https://packages.debian.org/jessie/rdiff-backup&#34;&gt;Debian
packages version 1.2.8&lt;/a&gt; while
&lt;a href=&#34;https://pkgs.alpinelinux.org/packages?name=rdiff-backup&amp;amp;branch=&amp;amp;repo=&amp;amp;arch=&amp;amp;maintainer=&#34;&gt;Alpine packages version
1.3.3&lt;/a&gt;.
I found this to be an odd decision for Alpine.  &lt;a href=&#34;http://www.nongnu.org/rdiff-backup/&#34;&gt;Both versions were released in
March 2009&lt;/a&gt; and haven&amp;rsquo;t had any update
since then.  Version 1.2.8 is marked as stable whereas 1.3.3 is marked as
development/unstable.  I don&amp;rsquo;t know the internal differences between the two
versions, but I checked other distributions like
&lt;a href=&#34;https://www.archlinux.org/packages/?q=rdiff-backup&#34;&gt;Arch&lt;/a&gt; and they also package
version 1.2.8 instead of 1.3.3.&lt;/p&gt;

&lt;p&gt;So, in order to get the version 1.2.8 in Alpine I took the easy route and
installed it manually.  After having done this, I realize that maybe it would
have been much better to learn about the Alpine build system and build the
package by reverting the &lt;a href=&#34;http://git.alpinelinux.org/cgit/aports/commit/main/rdiff-backup/APKBUILD?id=b633874f5c8b490cbd371338f7fb7b8f649ca009&#34;&gt;commit that updated rdiff-backup from 1.2.8 to
1.3.3&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;build-and-install&#34;&gt;Build and install&lt;/h1&gt;

&lt;p&gt;Anyhow, here&amp;rsquo;s how I installed rdiff-backup 1.2.8 manually:&lt;/p&gt;

&lt;p&gt;We first install rdiff-backup dependencies plus the packages required to build
rdiff-backup from source.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apk add librsync
apk add gcc librsync-dev python-dev musl-dev patch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We download the sources of rdiff-backup-1.2.8, check the hash sum to verify that
we got it right and we extract them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir tmp
cd tmp/
wget http://savannah.nongnu.org/download/rdiff-backup/rdiff-backup-1.2.8.tar.gz
[ &amp;quot;0d91a85b40949116fa8aaf15da165c34a2d15449b3cbe01c8026391310ac95db&amp;quot; \
    = $(sha256sum rdiff-backup-1.2.8.tar.gz | cut -d &amp;quot; &amp;quot; -f 1) ] &amp;amp;&amp;amp; echo OK
tar xzf rdiff-backup-1.2.8.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we download the required patch to build rdiff-backup with librsync-1.0.0,
in this case, from the Arch package git repository.  We check the patch and
apply it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://git.archlinux.org/svntogit/community.git/plain/trunk/rdiff-backup-1.2.8-librsync-1.0.0.patch?h=packages/rdiff-backup \
    -O rdiff-backup-1.2.8-librsync-1.0.0.patch
[ &amp;quot;a00d993d5ffea32d58a73078fa20c90c1c1c6daa0587690cec0e3da43877bf12&amp;quot; \
    = $(sha256sum rdiff-backup-1.2.8-librsync-1.0.0.patch | cut -d &amp;quot; &amp;quot; -f 1) ] &amp;amp;&amp;amp; echo OK
cd rdiff-backup-1.2.8/
patch -Np1 -i ../rdiff-backup-1.2.8-librsync-1.0.0.patch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are ready to build rdiff-backup and install it in the system.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;python setup.py build
python setup.py install --prefix=/usr --root=/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We must not forget to add the newly installed files in the local backup
database, so that they are stored permanently.  I deliberately skip the docs.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lbu add /usr/lib/python2.7/site-packages/rdiff_backup* /usr/bin/rdiff-backup*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After we are done, we can remove the packages we used to build rdiff-backup.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apk del gcc librsync-dev python-dev musl-dev patch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now rdiff-backup works correctly from my Debian laptop to my Alpine Raspberry Pi
:)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Raspberry Pi: git server (cgit with lighttpd)</title>
      <link>https://dhole.github.io/post/raspberry_pi_git/</link>
      <pubDate>Fri, 21 Oct 2016 15:14:27 -0700</pubDate>
      
      <guid>https://dhole.github.io/post/raspberry_pi_git/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In this post I will explain what&amp;rsquo;s required to set up a git server.  We&amp;rsquo;ll use
&lt;a href=&#34;https://git.zx2c4.com/cgit/&#34;&gt;cgit&lt;/a&gt; to provide a web interface and also allow
cloning/pulling through HTTP.  ssh will also be available for cloning/pulling
and pushing.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll setup two groups of repositories: a public and a private one.&lt;/p&gt;

&lt;h1 id=&#34;cgit&#34;&gt;Cgit&lt;/h1&gt;

&lt;p&gt;First of all, we&amp;rsquo;ll create a &lt;em&gt;git&lt;/em&gt; user and move it&amp;rsquo;s home to the encrypted
partition.  For convenience we&amp;rsquo;ll also link that home directory to &lt;code&gt;/git&lt;/code&gt;.  This
will be useful to have nice paths for our repositories.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;adduser git
lbu add /home/git/

rmdir /home/git
ln -sf /mnt/disk/git /home/
cp -R /home/green/.ssh /home/git/.ssh
chown -R git:git /home/git/
ln -s /home/git/ /git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally we install git, cgit and highlight (to provide code highlighting in
cgit).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apk add highlight git cgit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cgit comes with a default script that will call highlight, but unfortunately
it&amp;rsquo;s expecting version 2 of highlight.  We&amp;rsquo;ll copy the script and change it to
use the argument format of version 3 of highlight (the line is already there, we
just comment the version 2 and uncomment the version 3).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /usr/lib/cgit/filters/syntax-highlighting.sh /usr/lib/cgit/filters/syntax-highlighting3.sh
vim /usr/lib/cgit/filters/syntax-highlighting3.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- /usr/lib/cgit/filters/syntax-highlighting.sh
+++ /usr/lib/cgit/filters/syntax-highlighting3.sh
@@ -115,7 +115,7 @@
 # found (for example) on EPEL 6.
 #
 # This is for version 2
-exec highlight --force -f -I -X -S &amp;quot;$EXTENSION&amp;quot; 2&amp;gt;/dev/null
+#exec highlight --force -f -I -X -S &amp;quot;$EXTENSION&amp;quot; 2&amp;gt;/dev/null

 # This is for version 3
-#exec highlight --force -f -I -O xhtml -S &amp;quot;$EXTENSION&amp;quot; 2&amp;gt;/dev/null
+exec highlight --force -f -I -O xhtml -S &amp;quot;$EXTENSION&amp;quot; 2&amp;gt;/dev/null
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;lbu add /usr/lib/cgit/filters/syntax-highlighting3.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Highlight uses css to color the code, so we need to add some lines specifying
the colors we want to the css file cgit uses.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /usr/share/webapps/cgit/cgit.css /usr/share/webapps/cgit/cgit-highlight.css
vim /usr/share/webapps/cgit/cgit-highlight.css
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;--- /usr/share/webapps/cgit/cgit.css
+++ /usr/share/webapps/cgit/cgit-highlight.css
@@ -809,3 +809,20 @@
 div#cgit table.ssdiff td.space div {
        min-height: 3em;
 }
+
+body.hl { background-color:#e0eaee; }
+pre.hl  { color:#000000; background-color:#e0eaee; font-size:10pt; font-family:&#39;Courier New&#39;,monospace;}
+.hl.num { color:#b07e00; }
+.hl.esc { color:#ff00ff; }
+.hl.str { color:#bf0303; }
+.hl.pps { color:#818100; }
+.hl.slc { color:#838183; font-style:italic; }
+.hl.com { color:#838183; font-style:italic; }
+.hl.ppc { color:#008200; }
+.hl.opt { color:#000000; }
+.hl.ipl { color:#0057ae; }
+.hl.lin { color:#555555; }
+.hl.kwa { color:#000000; font-weight:bold; }
+.hl.kwb { color:#0057ae; }
+.hl.kwc { color:#000000; font-weight:bold; }
+.hl.kwd { color:#010181; }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;lbu add /usr/share/webapps/cgit/cgit-highlight.css
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As mentioned in the introduction, we will setup two folders, one for private repositories and the other one for public ones.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /mnt/disk
mkdir -p git/pub
mkdir -p git/priv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For our setup we will use a general cgit configuration files, and two
specialized ones for the public and private folders.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir /etc/cgit
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/cgit/cgitrc
css=/cgit/cgit-highlight.css
logo=/cgit/cgit.png
source-filter=/usr/lib/cgit/filters/syntax-highlighting3.sh
enable-git-config=1
enable-index-owner=0
enable-commit-graph=1
enable-index-links=1
enable-log-linecount=1
enable-log-filecount=1
#cache-size=512
robots=noindex, nofollow
root-title=Dhole&#39;s git repositories
root-desc=my personal repositories
remove-suffix=1
clone-prefix=https://lizard.kyasuka.com/cgit/cgit.cgi ssh://git@lizard.kyasuka.com:
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/cgit/cgitrc.public
include=/etc/cgit/cgitrc
clone-prefix=https://lizard.kyasuka.com/cgit/cgit.cgi ssh://git-kyasuka/git/pub
section=Public
scan-path=/mnt/distk/git/pub/
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/cgit/cgitrc.private
include=/etc/cgit/cgitrc
clone-prefix=https://lizard.kyasuka.com/private/cgit/cgit.cgi ssh://git-kyasuka/git/priv
section=Private
scan-path=/mnt/disk/git/priv/
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And finally, we create a new configuration file for lighttpd which will call
cgit via the cgi interface.  We are using the public and private configurations
by setting the &lt;code&gt;CGIT_CONFIG&lt;/code&gt; environment variable depending on the url path.
Remember to follow the previous post to add http auth to the urls that start
with &lt;code&gt;/private&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/lighttpd/cgit.conf
server.modules += (&amp;quot;mod_redirect&amp;quot;,
                   &amp;quot;mod_alias&amp;quot;,
                   &amp;quot;mod_cgi&amp;quot;,
                   &amp;quot;mod_fastcgi&amp;quot;,
                   &amp;quot;mod_rewrite&amp;quot;,
                   &amp;quot;mod_alias&amp;quot;,)

var.webapps = &amp;quot;/usr/share/webapps/&amp;quot;
$HTTP[&amp;quot;url&amp;quot;] =~ &amp;quot;^/cgit&amp;quot; {
        setenv.add-environment += ( &amp;quot;CGIT_CONFIG&amp;quot; =&amp;gt; &amp;quot;/etc/cgit/cgitrc.public&amp;quot; )
        server.document-root = webapps
        server.indexfiles = (&amp;quot;cgit.cgi&amp;quot;)
        cgi.assign = (&amp;quot;cgit.cgi&amp;quot; =&amp;gt; &amp;quot;&amp;quot;)
        mimetype.assign = ( &amp;quot;.css&amp;quot; =&amp;gt; &amp;quot;text/css&amp;quot; )
}
url.redirect = (
        &amp;quot;^/git/(.*)$&amp;quot; =&amp;gt; &amp;quot;/cgit/cgit.cgi/$1&amp;quot;,
)
$HTTP[&amp;quot;url&amp;quot;] =~ &amp;quot;^/private/cgit&amp;quot; {
        #url.rewrite-once = ( &amp;quot;^/private/cgit/(.*)&amp;quot; =&amp;gt; &amp;quot;/cgit/$1&amp;quot; )
        alias.url = ( &amp;quot;/private/&amp;quot; =&amp;gt; &amp;quot;/usr/share/webapps/&amp;quot; )
        setenv.add-environment += ( &amp;quot;CGIT_CONFIG&amp;quot; =&amp;gt; &amp;quot;/etc/cgit/cgitrc.private&amp;quot; )
        server.document-root = webapps
        server.indexfiles = (&amp;quot;cgit.cgi&amp;quot;)
        cgi.assign = (&amp;quot;cgit.cgi&amp;quot; =&amp;gt; &amp;quot;&amp;quot;)
        mimetype.assign = ( &amp;quot;.css&amp;quot; =&amp;gt; &amp;quot;text/css&amp;quot; )
}
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;vim /etc/lighttpd/lighttpd.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
...
# {{{ includes
...
include &amp;quot;cgit.conf&amp;quot;
...
# }}}
...
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We commit every file to permanent storage and restart the lighttpd server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lbu commit
rc-service lighttpd start
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We should be able to visit the cgit interface from a browser now.&lt;/p&gt;

&lt;h1 id=&#34;git-usage&#34;&gt;Git usage&lt;/h1&gt;

&lt;p&gt;To automate making new repositories I wrote the following simple script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /home/git/new-repo.sh
#! /bin/sh

folder=$1
name=$2
desc=&amp;quot;$3&amp;quot;

if [ &amp;quot;$#&amp;quot; -ne 3 ]
then
        echo &amp;quot;Usage: $0 {pub|priv} name description&amp;quot;
        exit 1
fi

if [ ! -d &amp;quot;$folder&amp;quot; ]
then
        echo &amp;quot;Group $folder doesn&#39;t exist.  use pub/priv.&amp;quot;
        exit 2
fi

if [ -d &amp;quot;$folder/$name&amp;quot;.git ]
then
        echo &amp;quot;$folder/$name already exists&amp;quot;
        exit 3
fi

if [ &amp;quot;$desc&amp;quot; == &amp;quot;&amp;quot; ]
then
        echo &amp;quot;Please, provide a description in the 3rd argument.&amp;quot;
        exit 4
fi

cd &amp;quot;$folder&amp;quot;
mkdir &amp;quot;$name&amp;quot;.git
cd &amp;quot;$name&amp;quot;.git
git init --bare
echo &amp;quot;$desc&amp;quot; &amp;gt; description

echo &amp;quot;$folder/$name is ready.&amp;quot;
echo &amp;quot;&amp;quot;
echo &amp;quot;  Create a new repository&amp;quot;
echo &amp;quot;&amp;quot;
echo &amp;quot;git clone ssh://git-kyasuka/git/$folder/$name.git&amp;quot;
echo &amp;quot;cd $name&amp;quot;
echo &amp;quot;touch README.md&amp;quot;
echo &amp;quot;git add README.md&amp;quot;
echo &amp;quot;git commit -m \&amp;quot;add README\&amp;quot;&amp;quot;
echo &amp;quot;git push -u origin master&amp;quot;
echo &amp;quot;&amp;quot;
echo &amp;quot;  Existing folder or Git repository&amp;quot;
echo &amp;quot;&amp;quot;
echo &amp;quot;cd existing_folder&amp;quot;
echo &amp;quot;git init&amp;quot;
echo &amp;quot;git remote add origin ssh://git-kyasuka/git/$folder/$name.git&amp;quot;
echo &amp;quot;git add .&amp;quot;
echo &amp;quot;git commit&amp;quot;
echo &amp;quot;git push -u origin master&amp;quot;
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, to create a new git repository I just do the following from my local
machine:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh git@lizard.kyasuka.com
./new-repo.sh pub test &amp;quot;This is a test repository&amp;quot;
exit
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;bonus&#34;&gt;Bonus&lt;/h1&gt;

&lt;p&gt;I had a few repositories in github, so I wrote the following python script to
clone them all into my server.  This will make the transition easier :)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /mnt/disk/git/import-github.py
#! /usr/bin/env python3

from urllib.request import urlopen, urlretrieve
import os, sys, re, subprocess

user = sys.argv[1]
content = urlopen(&#39;https://api.github.com/users/%s/repos&#39; % user).read()
content = content.decode(&#39;UTF-8&#39;)


clone_urls = re.findall(&#39;(?&amp;lt;=&amp;quot;clone_url&amp;quot;:)&amp;quot;[^&amp;quot;]*&amp;quot;,&#39;, content)
descriptions = re.findall(&#39;(?&amp;lt;=&amp;quot;description&amp;quot;:)(null|&amp;quot;[^&amp;quot;]*&amp;quot;),&#39;, content)

descriptions = [d.replace(&#39;&amp;quot;&#39;, &#39;&#39;) for d in descriptions]
os.chdir(&#39;pub&#39;)
for i in range(0, len(clone_urls)):
    clone_url = clone_urls[i]
    clone_url = clone_url[1:-2]
    print(clone_url)
    subprocess.run([&#39;git&#39;, &#39;clone&#39;, &#39;--bare&#39;, clone_url])
    with open(clone_url.split(&#39;/&#39;)[-1] + &#39;/description&#39;, &#39;w&#39;) as desc_file:
        desc_file.write(descriptions[i] + &#39;\n&#39;)
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that concludes my initial series of posts on setting up my Raspberry Pi 2 to
act as a git server.  I&amp;rsquo;m planning on setting up a backup system in the future,
so I may write about it too :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Raspberry Pi: setting up alpine, lighttpd and letsencrypt</title>
      <link>https://dhole.github.io/post/raspberry_pi_alpine_lighttpd/</link>
      <pubDate>Fri, 21 Oct 2016 15:14:27 -0700</pubDate>
      
      <guid>https://dhole.github.io/post/raspberry_pi_alpine_lighttpd/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In this post I will explain how to set up &lt;a href=&#34;https://alpinelinux.org/&#34;&gt;Alpine
Linux&lt;/a&gt; for the RPi, with the necessary configuration
for the RPi to power a USB hard drive, how to install lighttpd and configure
automatic renewal of TLS certificates with lestencrypt.&lt;/p&gt;

&lt;h1 id=&#34;alpine-linux&#34;&gt;Alpine Linux&lt;/h1&gt;

&lt;p&gt;Alpine Linux can be installed on te RPi following the &lt;a href=&#34;https://wiki.alpinelinux.org/wiki/Raspberry_Pi&#34;&gt;wiki
guide&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After instalation, we add a new user which we will use for logging in:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;adduser green
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After logging in with our new user (using password) we&amp;rsquo;ll add some ssh public
keys for future logins:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vi /home/green/.ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will also download some configurations files for Vim and tmux:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl https://gitlab.com/dhole/dot_files/raw/master/.tmux.conf -o ~/.tmux.conf
curl https://gitlab.com/dhole/dot_files/raw/master/.airline_tmux -o ~/.airline_tmux
curl https://gitlab.com/dhole/dot_files/raw/master/.vimrc_basic -o ~/.vimrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we will log in as root and store the files persistently:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lbu add /home/green/.ssh/authorized_keys
lbu add /home/green/.vimrc
lbu add /home/green/.tmux.conf
lbu add /home/green/.airline_tmux
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From now on everything will be done as root.  For convenience I open a tmux
session after logging in as my regular user, and get a root shell in one tmux
window.&lt;/p&gt;

&lt;p&gt;First we will configure the boot process of the RPI to allow the USB connections
to offer the maximum power allowed, otherwise the external hard drive will not
work properly.  We are also assigning the minimum amount of RAM to the GPU
because we&amp;rsquo;ll be using the RPI as a headless server.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# remount sd-card writeable
mount -o remount,rw /media/mmcblk0p1

# create rpi2/3 config
cat &amp;lt;&amp;lt; EOF &amp;gt; /media/mmcblk0p1/usercfg.txt
disable_splash=1
boot_delay=0
start_x=0
max_usb_current=1
gpu_mem=16
EOF

sync
reboot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we install the required packages for our needs, and delete the default HTTP
server that comes with busybox.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apk add vim sudo openssl bash lighttpd-mod_auth rsync
apk del mini_httpd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I will use a script to decrypt the USB hard disk partition.  I will be running
this script manually every time I reboot the RPI.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /root/startup.sh
#! /bin/sh

cryptsetup luksOpen /dev/sda1 disk
mkdir -p /mnt/disk
mount /dev/mapper/disk /mnt/disk/

rc-service lighttpd start
EOF

lbu add /root/startup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;lighttpd&#34;&gt;Lighttpd&lt;/h1&gt;

&lt;p&gt;We run the previous script to mount the encrypted partition in &lt;code&gt;/mnt/disk&lt;/code&gt; and
we&amp;rsquo;ll move some private folders there:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/root/startup.sh
mkdir /mnt/disk/alpine-root
cd /mnt/disk/alpine-root
mkdir -p etc/dehydrated var/log/lighttpd var/www
ln -sf /mnt/disk/alpine-root/etc/dehydrated/ /etc/dehydrated
ln -sf /mnt/disk/alpine-root/var/www/ /var/www
ln -sf /mnt/disk/alpine-root/var/log/lighttpd /var/log/
chown -R lighttpd:lighttpd /var/log/lighttpd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I want to enable HTTP auth for some paths in the HTTP server, so I&amp;rsquo;ll use a
script to add new triplets of user, realm and password.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir /etc/lighttpd/.htpasswd
cd /etc/lighttpd/.htpasswd/

cat &amp;lt;&amp;lt; EOF &amp;gt; hash.sh
#!/bin/sh
user=$1
realm=$2
pass=$3
hash=`echo -n &amp;quot;$user:$realm:$pass&amp;quot; | md5sum | cut -b -32`
echo &amp;quot;$user:$realm:$hash&amp;quot;
EOF

chmod 755 hash.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After this I can add a username and password for the &amp;lsquo;private&amp;rsquo; realm.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./hash.sh &#39;username&#39; &#39;private&#39; &#39;password&#39; &amp;gt; /etc/lighttpd/.htpasswd/lighttpd-htdigest.username
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now it&amp;rsquo;s time to configure lighttpd.  The file is already populated with the
default configuration, so I&amp;rsquo;m just showing the changes I added, copy them where
they belong as needed.  In the following configuration I&amp;rsquo;m configuring the
server to listen on port 80 to serve redirections to https; and I&amp;rsquo;m listening on
port 443 for the primary usage with sane security configurations.  I&amp;rsquo;ll be using
the certificate generated by the &lt;em&gt;dehydrated&lt;/em&gt; letsencrypt client, which will be
an elliptic curve key.  Finally I&amp;rsquo;m enabling http auth with the previous user
and password for all paths that start with &lt;code&gt;/private/&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim /etc/lighttpd/lighttpd.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;server.modules = (
...
    &amp;quot;mod_redirect&amp;quot;,
    &amp;quot;mod_access&amp;quot;,
    &amp;quot;mod_auth&amp;quot;,
    &amp;quot;mod_setenv&amp;quot;,
...
)
...
...
# {{{ includes
...
include &amp;quot;cgit.conf&amp;quot;
...
# }}}
...
...
$SERVER[&amp;quot;socket&amp;quot;] == &amp;quot;:443&amp;quot; {
  ssl.engine    = &amp;quot;enable&amp;quot;
  ssl.pemfile   = &amp;quot;/etc/dehydrated/certs/lizard.kyasuka.com/combined.pem&amp;quot;
  ssl.ca-file   = &amp;quot;/etc/dehydrated/certs/lizard.kyasuka.com/chain.pem&amp;quot;

  #### Mitigate BEAST attack:

  # A stricter base cipher suite. For details see:
  # http://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2011-3389
  # or
  # http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2011-3389

  ssl.cipher-list = &amp;quot;EECDH+AESGCM:EDH+AESGCM:AES128+EECDH:AES128+EDH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK&amp;quot;
  #
  # Make the server prefer the order of the server side cipher suite instead of the client suite.
  # This is necessary to mitigate the BEAST attack (unless you disable all non RC4 algorithms).
  # This option is enabled by default, but only used if ssl.cipher-list is set.
  ssl.honor-cipher-order = &amp;quot;enable&amp;quot;

  # Mitigate CVE-2009-3555 by disabling client triggered renegotiation
  # This option is enabled by default.
  #
  ssl.disable-client-renegotiation = &amp;quot;enable&amp;quot;
  #

  ssl.use-compression = &amp;quot;disable&amp;quot;
  ssl.use-sslv2 = &amp;quot;disable&amp;quot;
  ssl.use-sslv3 = &amp;quot;disable&amp;quot;

  ssl.dh-file = &amp;quot;/etc/ssl/dhparam.pem&amp;quot;
  ssl.ec-curve = &amp;quot;prime256v1&amp;quot;

  setenv.add-response-header = ( &amp;quot;Strict-Transport-Security&amp;quot; =&amp;gt; &amp;quot;max-age=15768000&amp;quot;) # six months
}
...
...
$HTTP[&amp;quot;url&amp;quot;] =~ &amp;quot;^/private/(.*)&amp;quot; {
  auth.backend = &amp;quot;htdigest&amp;quot;
  auth.backend.htdigest.userfile = &amp;quot;/etc/lighttpd/.htpasswd/lighttpd-htdigest.green&amp;quot;
  auth.require = ( &amp;quot;&amp;quot; =&amp;gt;
      (
      &amp;quot;method&amp;quot;  =&amp;gt; &amp;quot;digest&amp;quot;,
      &amp;quot;realm&amp;quot;   =&amp;gt; &amp;quot;private&amp;quot;,
      &amp;quot;require&amp;quot; =&amp;gt; &amp;quot;valid-user&amp;quot;
      ),
  )
}
...
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In order to protect against the &lt;a href=&#34;https://weakdh.org/&#34;&gt;Logjam Attack&lt;/a&gt; we&amp;rsquo;ll
generate a new Diffie-Hellman group of 4096 bits.  I first tried this on the RPi
but after 12h it hadn&amp;rsquo;t finished, so I did it on my laptop and transfered the
file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl dhparam -out /etc/ssl/dhparam.pem 4096
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;letsencrypt&#34;&gt;Letsencrypt&lt;/h1&gt;

&lt;p&gt;Now we install the &lt;a href=&#34;https://github.com/lukas2511/dehydrated/&#34;&gt;dehydrated letsencrypt
client&lt;/a&gt;.  I&amp;rsquo;m choosing this one
instead of the official one to avoid pulling all the python dependencies, and to
avoid running it as root.  dehydrated is written entirely in bash.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir /mnt/disk/alpine-root/git
cd /mnt/disk/alpine-root/git/
git clone https://github.com/lukas2511/dehydrated

mkdir /etc/dehydrated
cp /mnt/disk/alpine-root/git/dehydrated/docs/examples/config /etc/dehydrated/config
mkdir -p /var/www/localhost/htdocs/.well-known/acme-challenge

chown lighttpd:lighttpd -R /var/www

lbu inc /var/www
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we edit the default dehydrated config to use a different path to store the
challenge and to generate elliptic curve keys, using the &lt;a href=&#34;https://www.prime256v1.com&#34;&gt;NIST P-256
curve&lt;/a&gt;.  I would have preferred using the &lt;a href=&#34;https://ed25519.cr.yp.to/&#34;&gt;Ed25519
curve&lt;/a&gt;, but it&amp;rsquo;s not yet part of the TLS standard :(&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;vim /etc/dehydrated/config
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
WELLKNOWN=&amp;quot;/var/www/localhost/htdocs/.well-known/acme-challenge/&amp;quot;
...
KEY_ALGO=prime256v1
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we add the list of domains and subdomains that we want plan to use.  Every
line should be a space separated list of subdomains belonging to the same
domain.  I&amp;rsquo;m only using one subdomain for one domain.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/dehydrated/domains.txt
lizard.kyasuka.com
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we run the letsencrypt client to generate and sign the certificates, and
generate a file with the private key and certificate that lighttpd will use.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chown lighttpd:lighttpd -R /etc/dehydrated/

sudo -u lighttpd /mnt/disk/alpine-root/git/dehydrated/dehydrated -c

sudo -u lighttpd cat /etc/dehydrated/certs/lizard.kyasuka.com/privkey.pem \
/etc/dehydrated/certs/lizard.kyasuka.com/cert.pem \
&amp;gt; /etc/dehydrated/certs/lizard.kyasuka.com/combined.pem
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To automate the renewal process we&amp;rsquo;ll add an entry to the lighttpd user crontab.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo -u lighttpd crontab -e
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;42      5       *       *       *       /mnt/disk/alpine-root/git/dehydrated/dehydrated -c &amp;amp;&amp;amp; \
                                        cat /etc/dehydrated/certs/lizard.kyasuka.com/privkey.pem \
                                        /etc/dehydrated/certs/lizard.kyasuka.com/cert.pem \
                                        &amp;gt; /etc/dehydrated/certs/lizard.kyasuka.com/combined.pem &amp;amp;&amp;amp; \
                                        /mnt/disk/alpine-root/git/dehydrated/dehydrated -gc
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;last-details&#34;&gt;Last details&lt;/h1&gt;

&lt;p&gt;Finally, considering that Apline Linux runs from RAM we realize that if the RPi
powers off, we&amp;rsquo;ll lose al logs (except for lighttpd&amp;rsquo;s logs, which we are writing
directly to our encrypted partition).  It&amp;rsquo;s useful to read the logs after our
server goes down, so we add a crontab that will rsync the logs to the encrypted
parititon.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;crontab -e
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;...
...
*/15    *       *       *       *       ls /mnt/disk/alpine-root &amp;amp;&amp;amp; \
                                        rsync -a /var/log/dmesg /var/log/messages /mnt/disk/alpine-root/var/log/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, commit all the changes to store them permanently:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lbu commit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the next post I will explain how to use the RPi as a git server, with cgit a
the web interface.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Raspberry Pi 2 I/O benchmarks</title>
      <link>https://dhole.github.io/post/raspberry_pi_benchmarks/</link>
      <pubDate>Thu, 20 Oct 2016 15:03:12 -0700</pubDate>
      
      <guid>https://dhole.github.io/post/raspberry_pi_benchmarks/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m currently setting up a Raspberry Pi 2 as a home server for various services.
I&amp;rsquo;m gonna write a series of blog posts about how I configured my Raspberry Pi to
achieve my goals, which will be mainly setting up a git server and a backup
server.&lt;/p&gt;

&lt;h1 id=&#34;choice-of-distribution&#34;&gt;Choice of distribution&lt;/h1&gt;

&lt;p&gt;I discovered &lt;a href=&#34;https://alpinelinux.org/&#34;&gt;Alpine Linux&lt;/a&gt; while searching
lightweight distributions for the Raspberry Pi.  This is a lovely small Linux
distribution: one of the first things I noticed is how fast it runs on the RPi
due to using a ram filesystem by default; this is specially noticeable in the
RPi because usualy the operating system resides in the micro-SD card, which
usually offers really slow read and write operations.  Another really nice
feature is that it&amp;rsquo;s security-oriented, and as such the kernel is patched with
&lt;a href=&#34;https://www.grsecurity.net/&#34;&gt;grsecurity/PaX&lt;/a&gt; and the userland binaries (I
understand that means all packages- too) are compiled with hardening features:
&lt;a href=&#34;https://en.wikipedia.org/wiki/Position-independent_code&#34;&gt;Position Independent Executables
(PIE)&lt;/a&gt; and &lt;a href=&#34;http://wiki.osdev.org/Stack_Smashing_Protector&#34;&gt;stack
smashing protection&lt;/a&gt;.  This
distribution uses &lt;a href=&#34;https://www.musl-libc.org/&#34;&gt;musl libc&lt;/a&gt; instead of glib and
&lt;a href=&#34;https://busybox.net/&#34;&gt;busybox&lt;/a&gt; to provide all the basic utilities, decisions
that help making it small and lightweight.  I should also mention that OpenRC is
used for the init system (instead of following the current trend of switching to
systemd).&lt;/p&gt;

&lt;h1 id=&#34;personal-requirements&#34;&gt;Personal requirements&lt;/h1&gt;

&lt;p&gt;Now that I have choosen a distribution, I have a requierement for my setup: all
the personal data I store in the RPi (git repositories, backups, websites) must
be encrypted in the disk.&lt;/p&gt;

&lt;h1 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m mainly interested in how fast files can be written on the encrypted
partition.  This files will probably be comming from the network.&lt;/p&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;To achieve better I/O and to avoid damaging the micro-SD (or a USB stick) I&amp;rsquo;m
gonna use an external USB hard disk (western digital My Passport) for storage.&lt;/p&gt;

&lt;p&gt;The RPi will be connected to a 1 Gbps switch (which shouldn&amp;rsquo;t matter considering
that the Ethernet interface of all the RPis are &lt;sup&gt;10&lt;/sup&gt;&amp;frasl;&lt;sub&gt;100&lt;/sub&gt; Mbps).&lt;/p&gt;

&lt;h2 id=&#34;cryptsetup&#34;&gt;cryptsetup&lt;/h2&gt;

&lt;p&gt;This test will give us the encryption/decryption speeds running from memory, so
they represent an upper bound on the write speed that we can achieve in disk.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lizard:~/git/public/test.git$ cryptsetup benchmark
# Tests are approximate using memory only (no storage IO).
PBKDF2-sha1        42555 iterations per second for 256-bit key
PBKDF2-sha256      73635 iterations per second for 256-bit key
PBKDF2-sha512      33781 iterations per second for 256-bit key
PBKDF2-ripemd160   36408 iterations per second for 256-bit key
PBKDF2-whirlpool   11497 iterations per second for 256-bit key
#  Algorithm | Key |  Encryption |  Decryption
     aes-cbc   128b    12.6 MiB/s    14.8 MiB/s
 serpent-cbc   128b           N/A           N/A
 twofish-cbc   128b           N/A           N/A
     aes-cbc   256b    10.9 MiB/s    11.2 MiB/s
 serpent-cbc   256b           N/A           N/A
 twofish-cbc   256b           N/A           N/A
     aes-xts   256b    14.6 MiB/s    14.4 MiB/s
 serpent-xts   256b           N/A           N/A
 twofish-xts   256b           N/A           N/A
     aes-xts   512b    11.2 MiB/s    11.0 MiB/s
 serpent-xts   512b           N/A           N/A
 twofish-xts   512b           N/A           N/A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My encrypted partition is using AES-XTS (this mode is the current
recommendation) with 256 bit keys, so we achieve &lt;strong&gt;14.6 MiB/s&lt;/strong&gt; and &lt;strong&gt;14.4
MiB/s&lt;/strong&gt; for encryption (write) and decryption (read).&lt;/p&gt;

&lt;h2 id=&#34;fat32-write-speed-dd&#34;&gt;FAT32 write speed (dd)&lt;/h2&gt;

&lt;p&gt;For a baseline comparison, I test the write speed of an unencrypted FAT32 file
system.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lizard:/mnt/slowpoke# time dd bs=1M count=4096 if=/dev/zero of=test conv=fsync
4096+0 records in
4095+1 records out
real    11m 28.47s
user    0m 0.08s
sys     0m 45.25s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The measurement of write speed is &lt;strong&gt;5.95 MB/s&lt;/strong&gt;.  That&amp;rsquo;s much lower than what I
was expecting.  I achieve write speeds of 40 MB/s from my laptop on the same
external disk.&lt;/p&gt;

&lt;h2 id=&#34;luks-ext4-write-speed-dd&#34;&gt;LUKS + ext4 write speed (dd)&lt;/h2&gt;

&lt;p&gt;This test should theoretically give upper bound results for my setup.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lizard:/mnt/wd_ext# time dd bs=1M count=4096 if=/dev/zero of=test conv=fsync
4096+0 records in
4096+0 records out
real    21m 23.27s
user    0m 0.07s
sys     0m 36.35s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s just &lt;strong&gt;3.19 MB/s&lt;/strong&gt;, which is extremely slow.&lt;/p&gt;

&lt;h2 id=&#34;luks-ext4-rsync&#34;&gt;LUKS + ext4 (rsync)&lt;/h2&gt;

&lt;p&gt;This test measures exactly one of my use cases, as I plan to use rsync for my
backups.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; % rsync -v --progress movie.mp4 green-local:/mnt/disk/
movie.mp4
  1,991,346,871 100%    9.17MB/s    0:03:27 (xfr#1, to-chk=0/1)

sent 1,991,833,155 bytes  received 35 bytes  9,553,156.79 bytes/sec
total size is 1,991,346,871  speedup is 1.00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Surprisingly this one gives much better results than the &lt;code&gt;dd&lt;/code&gt; tests: &lt;strong&gt;9.11
MB/s&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;First of all, I don&amp;rsquo;t understand why the &lt;code&gt;dd&lt;/code&gt; tests performed so badly.  The
&lt;code&gt;fsync&lt;/code&gt; option should make sure that data is written to disk and not cached:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        conv=fsync      Physically write data out before finishing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Maybe there&amp;rsquo;s a bug in busybox&amp;rsquo;s dd?  Or am I missing something?  I was
expecting to find the same speeds as LUKS encryption speeds here.&lt;/p&gt;

&lt;p&gt;The rsync test gives us the best performance we could expect, considering that
the limit comes from the 100 Mbit Ethernet, we won&amp;rsquo;t be able to transfer data at
higher speeds than ~10 MB/s.  In this case, the usage of disk encryption isn&amp;rsquo;t
making things slower.&lt;/p&gt;

&lt;p&gt;So overall I&amp;rsquo;m expecting to get transfer speeds (including writing to the
encrypted partition) of about &lt;strong&gt;9-10 MB/s&lt;/strong&gt;.  I&amp;rsquo;m happy with this and I believe
it should suit my needs, as I plan do backups every day in my local network.&lt;/p&gt;

&lt;p&gt;In the next post I will explain how to set up a git server with a web interface.
Stay tunned!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>No more unencrypted emails to gpg contacts</title>
      <link>https://dhole.github.io/post/check_mail_gpg/</link>
      <pubDate>Sat, 04 Jun 2016 00:13:28 +0200</pubDate>
      
      <guid>https://dhole.github.io/post/check_mail_gpg/</guid>
      <description>

&lt;p&gt;I have been using mutt for about half a year already and I&amp;rsquo;m very happy with it.
The previous email client I used was Thunderbird (with the Enigmail extension to
handle GPG).  There were two main reasons that made me switch.&lt;/p&gt;

&lt;p&gt;The first one was that I often would like to check my email while I&amp;rsquo;m offline,
and it seems that Thunderbird is not very good at this.  Sometimes not all my
email would have been downloaded (just the headers), and I also found it
frustrating that after marking more than 50 emails as read while offline, they
would be marked as unread again once I went back online.  With mutt I&amp;rsquo;m using
mbsync (which apparently is faster than offlineimap) to sync my email to a local
folder with a cron job.  I couldn&amp;rsquo;t be happier.&lt;/p&gt;

&lt;p&gt;The other issue was that I like having many filters, and it was tedious to
customize filters in Thunderbird:  there&amp;rsquo;s no way to copy a filter and modify
it, and there&amp;rsquo;s a limit in the combinations of ANDs and ORs for fields.  I&amp;rsquo;m
using procmail now, which allows me save the filter configuration in plaintext
and define patterns with more flexibility.&lt;/p&gt;

&lt;p&gt;The setup for mutt took several weeks, but I never felt that I couldn&amp;rsquo;t
accomplish what I wanted (unlike in Thunderbird).  I&amp;rsquo;m using mutt with several
python and bash scripts that I wrote.&lt;/p&gt;

&lt;p&gt;But the reason for this post is an issue that I believe happens in every email
client (or should I say, MUA, to be more precise).  I&amp;rsquo;ve seen it happening to
people using both Thunderbird and mutt, and I bet it has happened in other
cases: sending an email to someone for which you have their GPG key unencrypted
unwillingly.  I&amp;rsquo;ve seen this happening in email replies with several
participants: after a few encrypted messages are exchanged, someone replies in
the clear, quoting all the previous messages.  I tried to avoid this by
configuring mutt to encrypt and sign by default, forcing me to set sign only
manually before sending every email that I can&amp;rsquo;t send encrypted (I&amp;rsquo;d like to
send all my emails encrypted, but not everybody has a GPG key :( ).&lt;/p&gt;

&lt;p&gt;So what happened?  I got so used to sending many unencrypted emails that I would
press &amp;ldquo;P S&amp;rdquo; (PGP setting, Sign only) before sending emails as a reflex act.  And
I sent an email unencrypted to a friend for which I have his GPG key :(&lt;/p&gt;

&lt;p&gt;So I thought: It&amp;rsquo;s a very rare case to want to send an unencrypted email to
someone for which you have their GPG key.  I think extensions like Enigmail
should give you a warning when this happens, to alert you about it.  In my case,
I solved it with a python script that inspects the email, and, if it&amp;rsquo;s
unencrypted and the recipient/s is/are in your GPG keyring it warns you about it
and returns an error.  The script stores a temporary file with the Message-ID so
that if you run it again with the same email it will properly send the email
without returning an error.&lt;/p&gt;

&lt;p&gt;Now, I only needed to configure mutt to use this script as the sendmail command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;per_account:set sendmail  = &amp;quot;$HOME/bin/check-mail-gpg /usr/bin/msmtp -a $my_email&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here goes the python script &lt;code&gt;check-mail-gpg&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#! /usr/bin/python3

import os
import sys
import subprocess
import email.parser
from email.header import decode_header
from email.utils import parseaddr

STATUS_FILE = &#39;/tmp/check-mail-gpg.tmp&#39;

def dec(header):
    head = decode_header(header)
    if len(head) == 1 and head[0][1] == None:
        return head[0][0]
    else:
        return &#39;&#39;.join([h.decode(enc) if enc else h.decode(&#39;ascii&#39;) \
                for (h,enc) in head])

def send_mail(mail):
    print(&#39;Calling external email client to send the email...&#39;)
    #return -1 # testing mode
    p = subprocess.Popen(sys.argv[1:], stdin=subprocess.PIPE)
    p.stdin.write(mail.encode(&#39;utf-8&#39;))
    p.stdin.close()
    return p.wait()

def main():
    mail = sys.stdin.read()
    heads = email.parser.Parser().parsestr(mail, headersonly=True)
    content = heads[&#39;Content-Type&#39;].split(&#39;;&#39;)[0].strip()
    print(&#39;Content is:&#39;, content)

    if content == &#39;multipart/encrypted&#39;:
        print(&#39;Ok: encrypted mail, we can return now...&#39;)
        sys.exit(send_mail(mail))

    addrs = [parseaddr(addr) for addr in heads[&#39;To&#39;].split(&#39;,&#39;)]
    print(&#39;Found emails:&#39;, addrs)

    gpg_cnt = 0
    for name, addr in addrs:
        print(&#39;Looking for&#39;, addr, &#39;in the keyring...&#39;)
        res = subprocess.call([&#39;gpg&#39;, &#39;--list-keys&#39;, addr],
                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        if res == 0:
            gpg_cnt += 1

    if gpg_cnt == 0:
        print(&#39;Ok: no email found in the gpg keyring, we can return now...&#39;)
        sys.exit(send_mail(mail))

    if not os.path.exists(STATUS_FILE):
        open(STATUS_FILE, &#39;w&#39;).close()

    msg_id = heads[&#39;Message-ID&#39;]
    msg_id_prev = &#39;&#39;
    with open(STATUS_FILE, &#39;r&#39;) as f:
        msg_id_prev = f.read()

    if msg_id.strip() == msg_id_prev.strip():
        sys.exit(send_mail(mail))
    else:
        with open(STATUS_FILE, &#39;w&#39;) as f:
            f.write(msg_id)
        print(&#39;Alert: trying to send an unencrypted email to&#39;, addrs,
                &#39;, for which some gpg keys were found in the keyring!&#39;)
        print(&#39;Try again if you are sure to send this message unencrypted.&#39;)
        sys.exit(1)

if __name__ == &#39;__main__&#39;:
    main()
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;update&#34;&gt;Update&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;ve been told about the option &lt;code&gt;crypt_opportunistic_encrypt&lt;/code&gt; in mutt, which
provides a feature very similar to what I was looking for.  This option will
automatically enable encryption when the recipient has a GPG key in your
keyring.&lt;/p&gt;

&lt;p&gt;From mutt&amp;rsquo;s man page:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;3.41. crypt_opportunistic_encrypt&lt;/p&gt;

&lt;p&gt;Type: boolean Default: no&lt;/p&gt;

&lt;p&gt;Setting this variable will cause Mutt to automatically enable and disable
encryption, based on whether all message recipient keys can be located by
mutt.&lt;/p&gt;

&lt;p&gt;When this option is enabled, mutt will determine the encryption setting each
time the TO, CC, and BCC lists are edited. If $edit_headers is set, mutt will
also do so each time the message is edited.&lt;/p&gt;

&lt;p&gt;While this is set, encryption settings can&amp;rsquo;t be manually changed. The pgp or
smime menus provide an option to disable the option for a particular message.&lt;/p&gt;

&lt;p&gt;If $crypt_autoencrypt or $crypt_replyencrypt enable encryption for a message,
this option will be disabled for the message. It can be manually re-enabled in
the pgp or smime menus. (Crypto only)&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible builds on Debian for GSoC 2015, 1st update</title>
      <link>https://dhole.github.io/post/reproducible_builds_debian_gsoc2015_update_1/</link>
      <pubDate>Thu, 06 Aug 2015 20:12:15 +0200</pubDate>
      
      <guid>https://dhole.github.io/post/reproducible_builds_debian_gsoc2015_update_1/</guid>
      <description>

&lt;p&gt;This is the second blog post I&amp;rsquo;m writing about my experiences contributing to Debian for Google Summer of Code 2015 (check my &lt;a href=&#34;https://dhole.github.io/post/reproducible_builds_debian_gsoc2015/&#34;&gt;first post&lt;/a&gt;)&lt;/p&gt;

&lt;h1 id=&#34;status-update&#34;&gt;Status update&lt;/h1&gt;

&lt;h2 id=&#34;first-month&#34;&gt;First month&lt;/h2&gt;

&lt;p&gt;It&amp;rsquo;s been two months and a few days since the GSoC started. During the first month I worked on fixing specific packages, mainly concerning issues with timestamps, which is a very common source of unreproducibility. In many cases, during the build process files are compressed into gzip or zip archives, which store the creation time of files in the metadata. This can lead to unreproducible results when there is timezone variation between builds (easily fixed setting the timezone to UTC before the compression happens). In some cases the compressed files are generated during the build, and thus add build times in the metadata of compressed files (in this case the creation date of the files needs to be normalized somehow).&lt;/p&gt;

&lt;p&gt;As explained in my &lt;a href=&#34;https://wiki.debian.org/SummerOfCode2015/StudentApplications/EduardSanou&#34;&gt;application&lt;/a&gt;, I finished exams on the end of June, that&amp;rsquo;s why I chose to work on small fixes first, so that I could make the most out of my time between studying and finishing university projects and reports.
I&amp;rsquo;m happy with my first month, as I have worked as originally planned. Actually, my estimation of the number of bugs I could submit every week was surpassed in reality!&lt;/p&gt;

&lt;h2 id=&#34;second-month&#34;&gt;Second month&lt;/h2&gt;

&lt;p&gt;Once the university was over, I started dedicating myself fully to the project. This allowed me to start working on toolchain fixes, following my original plan on working with timestamp related issues.&lt;/p&gt;

&lt;p&gt;In particular I have been working a lot in implementing a &lt;a href=&#34;https://wiki.debian.org/ReproducibleBuilds/TimestampsProposal&#34;&gt;proposal for deterministic timestamps&lt;/a&gt; that appeared in the reproducible builds project. The idea is to define an environment variable called &lt;code&gt;SOURCE_DATE_EPOCH&lt;/code&gt; that contains a known timestamp in Unix epoch format. With this variable exported, tools that would embed the localtime in their generated or processed files, can use this externally supplied date. This would happen only if &lt;code&gt;SOURCE_DATE_EPOCH&lt;/code&gt; is exported, so the behaviour of the tool wouldn&amp;rsquo;t change if the variable is not set.&lt;/p&gt;

&lt;p&gt;The first package I patched to implement this behaviour was &lt;a href=&#34;https://gcc.gnu.org/ml/gcc-patches/2015-06/msg02210.html&#34;&gt;gcc&lt;/a&gt;. The reason behind this is that there are about 420 unreproducible packages due to using the &lt;code&gt;__DATE__&lt;/code&gt;, &lt;code&gt;__TIME__&lt;/code&gt; and &lt;code&gt;__TIMESTAMP__&lt;/code&gt; C macros. My patch changes the behavior of the macros &lt;code&gt;__DATE__&lt;/code&gt; and &lt;code&gt;__TIME__&lt;/code&gt; if &lt;code&gt;SOURCE_DATE_EPOCH&lt;/code&gt; is exported. I submitted this patch to the gcc-patches list. Even though there was some interesting discussions in the list, the patch has not been accepted yet. Seeing how the reproducible builds idea is gaining momentum and becoming widespread, I&amp;rsquo;m positive that at some point the gcc people will be more receptive for such patch.&lt;/p&gt;

&lt;p&gt;The second work with &lt;code&gt;SOURCE_DATE_EPOCH&lt;/code&gt; was in &lt;a href=&#34;https://bugs.debian.org/791823&#34;&gt;debhelper&lt;/a&gt;; I patched this building tool to export the variable with the latest debian/changelog entry timestamp. With this patch, all the tools that run under dh will be able to use it to embed deterministic timestamps. Unfortunately some parts of the build process of some packages don&amp;rsquo;t happen under debhelper, so the variable needs to be exported in a different way.&lt;/p&gt;

&lt;p&gt;Having submitted the debhelper patch allowed many packages to become reproducible after the tools that embedded timestamps were patched to honour &lt;code&gt;SOURCE_DATE_EPOCH&lt;/code&gt;. As of today, the toolchain packages I have patched to do that are: &lt;a href=&#34;https://gcc.gnu.org/ml/gcc-patches/2015-06/msg02210.html&#34;&gt;gcc&lt;/a&gt;, &lt;a href=&#34;https://bugs.debian.org/791815&#34;&gt;libxslt&lt;/a&gt;, &lt;a href=&#34;https://bugs.debian.org/792687&#34;&gt;gettext&lt;/a&gt;, &lt;a href=&#34;https://bugs.debian.org/794004&#34;&gt;ghostscript&lt;/a&gt; and &lt;a href=&#34;https://bugs.debian.org/794681&#34;&gt;qt4-x11 (qhelpgenerator)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I have also continued working on fixing individual packages affected by timestamps, random orderings (such as the ones from listing hash keys) and locale depending orderings; I have tagged packages in our infrastructure to note what kind of issue makes them unreproducible; I have updated some parts of the &lt;a href=&#34;https://wiki.debian.org/ReproducibleBuilds&#34;&gt;Reproducible Builds Wiki&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;impressions-about-reproducible-builds&#34;&gt;Impressions about reproducible builds&lt;/h1&gt;

&lt;p&gt;The work I did during the first month felt a bit tedious sometimes: it didn&amp;rsquo;t require much creativity or thinking as most of the fixes where quite mechanical, following a recipe. After I became free from university duties, I started looking into less trivial issues, which require more deep investigation and feel more rewarding once they are fixed. I also worked on toolchain fixes, which need more work and need more care. Fixing toolchain packages feels particularly rewarding because they can cause many packages to become reproducible at once.&lt;/p&gt;

&lt;p&gt;There is a very active community in the reproducible builds project! It&amp;rsquo;s great to see so many people contributing to this project spending so many hours and putting so much effort. I&amp;rsquo;ve felt very welcome from the beginning and I have gotten kind replies and helpful answers to all the questions and doubts I&amp;rsquo;ve had, both from my mentor and from the other people in the project.&lt;/p&gt;

&lt;p&gt;I want to add that I&amp;rsquo;m still amazed by the awesome infrastructure set up for the reproducible builds project. The team is using a Jenkins machine to continuously build packages to check for reproducibility, with irc notifications for changes, and also with a really useful web interface to list all the packages organized by issues that allows exploring them individually with all the available information. Also not only the infrastructure is used to build Debian amd64 packages, but also FreeBSD, NetBSD, &lt;a href=&#34;https://reproducible.debian.net/openwrt/openwrt.html&#34;&gt;OpenWRT&lt;/a&gt;, &lt;a href=&#34;https://reproducible.debian.net/coreboot/coreboot.html&#34;&gt;coreboot&lt;/a&gt; and lately Debian armhf with the help of a few new arm nodes.&lt;/p&gt;

&lt;h1 id=&#34;impressions-about-working-on-a-free-software-project&#34;&gt;Impressions about working on a free software project&lt;/h1&gt;

&lt;p&gt;This was my first time working on a community driven free software project and I&amp;rsquo;ve learned so many things.&lt;/p&gt;

&lt;p&gt;Something I learned during the first days, which is even more present in such wide project like the reproducible builds, is that contributing is not just writing patches for the features you want; you also need to convince the maintainer of the package to accept the patch! I was a bit surprised at the beginning because even if this is a Debian project, that aims to make changes to the whole distribution, decisions are not absolute for the whole Debian project. After taking decisions within the reproducible builds teams on how to approach things, we need to convince the rest of the Debian developers (mainly maintainers) to follow them, as they are allowed to disagree. So it is required to work together for solutions that makes everyone comfortable, usually with discussions on mailing lists or irc.&lt;/p&gt;

&lt;p&gt;There is another fact that I wasn&amp;rsquo;t expecting before getting involved in this project. The kind of teamwork I have done previously involves having a leader who decides how stuff is done, who takes decisions when needed and oversees the whole project. There seems to be a different philosophy in Debian. Instead of having a leader, everyone tries their best, trying to convince the others that their solution is good, often by showing an implementation of the solution and providing proof that it works, rather than trying to get the solution accepted before coding it. Also, solutions and ideas are valued for their quality rather than by the position of the person submitting them, and there is no hierarchy within the group: all comments and advices are taken equally, valuing their usefulness regardless of who gives them.&lt;/p&gt;

&lt;p&gt;Usually there are no votes when deciding things. Members try their best on their approaches, trying to convince others as best as they can. And even if someone disagrees they may end up accepting the solution if they don&amp;rsquo;t manage to convince the original proposer of doing things differently. The idea is to spend more time working and coding than arguing and deciding on the way to do things. So far I&amp;rsquo;ve seen this approach to be very efficient :)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve been told by my mentor that for difficult cases there exist a &lt;a href=&#34;https://www.debian.org/devel/tech-ctte&#34;&gt;Debian committee&lt;/a&gt; that helps mediate on disagreements, but that is only used as a last option, probably when the discussion gets heated up.&lt;/p&gt;

&lt;h2 id=&#34;personal-experience&#34;&gt;Personal experience&lt;/h2&gt;

&lt;p&gt;Overall I&amp;rsquo;m very happy to finally having set my foot in the free software community, where I&amp;rsquo;m able to contribute to the kind of software I have been using for years. The sense of community in Debian is really big, and everyone is invited to participate.&lt;/p&gt;

&lt;p&gt;I think that Google is doing an awesome job with the Google Summer of Code, not only because it gives a lot to free software but because it helps students to join the free software world as contributors (which is something that may be difficult to get into when you don&amp;rsquo;t know how to begin, as it happened to myself for some time). I plan to continue contributing to the free software world, and I&amp;rsquo;d encourage anyone to find projects to get involved and contribute as well!&lt;/p&gt;

&lt;p&gt;Happy hacking to everyone!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reproducible builds on Debian for GSoC 2015</title>
      <link>https://dhole.github.io/post/reproducible_builds_debian_gsoc2015/</link>
      <pubDate>Sun, 10 May 2015 17:14:05 +0200</pubDate>
      
      <guid>https://dhole.github.io/post/reproducible_builds_debian_gsoc2015/</guid>
      <description>

&lt;p&gt;This is the first blog post of a series I will be writing about my experiences contributing to Debian for Google Summer of Code 2015.&lt;/p&gt;

&lt;h1 id=&#34;a-bit-about-myself&#34;&gt;A bit about myself&lt;/h1&gt;

&lt;p&gt;I&amp;rsquo;m a Spanish student doing a master&amp;rsquo;s in Computer Science in Barcelona. I graduated on Electrical Engineering (we call it Telecommunications here). I&amp;rsquo;ve always been interested in computing and programming and I have worked on several projects on my own using C, python and go. My main interests in the field are programming languages, security, cryptography, distributed and decentralized systems and embedded systems.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m an advocate of free software, I try to use it as much as I&amp;rsquo;m able to in my devices and also try to convince my friends and family of its benefits. I have been using GNU/Linux for nearly ten years as my main operating system and I have tried several *BSD&amp;rsquo;s recently.&lt;/p&gt;

&lt;p&gt;One of my latest personal projects is a &lt;a href=&#34;https://github.com/Dhole/miniBoy&#34;&gt;gameboy emulator&lt;/a&gt; written in C (still work in progress) which already plays many games (without sound though) . You can find other minor projects in my &lt;a href=&#34;https://github.com/Dhole&#34;&gt;github page&lt;/a&gt; (I try to publish all the code I write online, under free software licence)&lt;/p&gt;

&lt;p&gt;After so many years of using free software and benefiting from it, I thought it was about time to contribute back! That&amp;rsquo;s why I gave GSoC a try and applied to work on the Reproducible Builds project for Debian :) And I got accepted!&lt;/p&gt;

&lt;h1 id=&#34;reproducible-builds&#34;&gt;Reproducible Builds&lt;/h1&gt;

&lt;p&gt;The idea behind this project is that currently many packages aren&amp;rsquo;t built in a reproducible manner; that is, they contain timestamps, building machine name, unique IDs, and results from other processes that happen differently between machines, like file ordering in compressed files. The project aims to patch all the Debian packages / the building scripts in order to generate the same binary (bit by bit) independently of the machine, timezone, etc where it is built. This way, a cryptographic hash of the built package can be distributed and many people can rebuild the package to verify that the binary in the repositories indeed corresponds to the right source code by means of comparing the hash.&lt;/p&gt;

&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;One of the main advantages of the free software is that source code is available for peer review. This makes it easier for users to trust their software, as they can check the source to verify that the program is not doing anything bad. Even if the user doesn&amp;rsquo;t do that, they can trust the wider community with that task. But many distributions serve packages in binary form, so how do we know that the binary comes from the publicly available source code? The current solution is that the developers who build the packages sign them cryptographically; but this lands all the trust to the developer and the machines used for building.&lt;/p&gt;

&lt;p&gt;I became interested in this topic with a &lt;a href=&#34;https://www.youtube.com/watch?v=5pAen7beYNc&#34;&gt;very nice talk&lt;/a&gt; given at 31c3 by Mike Perry from Tor and Seth Schoen from the EFF. They focused on reproducible builds applied to the tor browser bundle, showing a small demo of how a building machine could be compromised to add hidden functionalities when compiling code (so that the developer could be signing a compromised package without their knowledge).&lt;/p&gt;

&lt;h2 id=&#34;benefits&#34;&gt;Benefits&lt;/h2&gt;

&lt;p&gt;There are two main groups who benefit with reproducible builds:&lt;/p&gt;

&lt;h3 id=&#34;for-users&#34;&gt;For users&lt;/h3&gt;

&lt;p&gt;The user can be more secure when installing packages in binary form since they don&amp;rsquo;t need to trust a specific developer or building machine. Even if they don&amp;rsquo;t rebuild the package by themselves to verify it, there would be others doing so, who will easily alert the community when the binary doesn&amp;rsquo;t match the source code.&lt;/p&gt;

&lt;h3 id=&#34;for-developers&#34;&gt;For developers&lt;/h3&gt;

&lt;p&gt;The developer no longer has the responsibility of using his identity to sign the package for wide distribution, nor is that much responsible of the damage to users if their machine is compromised to alter the building process, since the community will easily detect it and alert them.&lt;/p&gt;

&lt;p&gt;This later point is specially useful with secure and privacy aware software. The reason is that there are many powerful organizations around the world with interest on having backdoors in widely used software, be it to spy on users or to target specific groups of people. Considering the amount of money these organizations have for such purposes, it&amp;rsquo;s not hard to imagine that they could try to blackmail developers into adding such backdoors on the built packages. Or they could try to compromise the building machine. With reproducible builds the developer is safer, as such attack is no longer useful.&lt;/p&gt;

&lt;h1 id=&#34;reproducible-builds-in-debian&#34;&gt;Reproducible Builds in Debian&lt;/h1&gt;

&lt;p&gt;The &lt;a href=&#34;https://wiki.debian.org/ReproducibleBuilds&#34;&gt;project&lt;/a&gt; kicked-off at Debian at mid 2013 , leaded by Lunar and soon followed by many other developers (h01ger, deki, mapreri, &amp;hellip;). Right now about 80% of the packages in the unstable branch of Debian can be built reproducibly. The project is very active, with many developers sending &lt;a href=&#34;https://bugs.debian.org/cgi-bin/pkgreport.cgi?usertag=reproducible-builds@lists.alioth.debian.org&#34;&gt;patches&lt;/a&gt; every week.&lt;/p&gt;

&lt;p&gt;A machine running &lt;a href=&#34;https://reproducible.debian.net/reproducible.html&#34;&gt;Jenkins&lt;/a&gt; (which was set up at the end of 2012 for other purposes) is being used since late 2014 to continuously build packages in different settings to check if they are built reproducibly or not.&lt;/p&gt;

&lt;p&gt;In order to analyze why packages fail to build reproducibly, a tool called &lt;strong&gt;debbindiff&lt;/strong&gt; has been developed, which is able to output in text or html form a smart diff of two builds.&lt;/p&gt;

&lt;p&gt;Another tool called &lt;strong&gt;strip-nondeterminism&lt;/strong&gt; has been developed to remove non-determinism from files during the building process.&lt;/p&gt;

&lt;p&gt;For this GSoC I plan on helping improving these tools (mainly debbindiff), write many patches to achieve reproducibility in more packages and write documentation about it. Some of the packages fail to build reproducibly due to specifics of their building processes, whereas others fail due to the usage of toolchains that add non-determinism. I&amp;rsquo;ll focus more on the later ones in order to improve the state more packages. akira will also be working on this project for this GSoC.&lt;/p&gt;

&lt;p&gt;Finally, I just want to add that I&amp;rsquo;m looking forward to contribute to Debian, meet the community and learn more about the internals of this awesome distribution!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Full disk encryption on Samsung Chromebook with Arch Linux</title>
      <link>https://dhole.github.io/post/full_disk_encryption_samsung_chromebook/</link>
      <pubDate>Fri, 01 May 2015 23:58:40 +0200</pubDate>
      
      <guid>https://dhole.github.io/post/full_disk_encryption_samsung_chromebook/</guid>
      <description>

&lt;p&gt;In this post I will explain the procedure I followed to have an Arch Linux
install on a Samsung Chromebook 1 (XE303C12-A01US) with full disk encryption
using kernel 3.8.&lt;/p&gt;

&lt;h1 id=&#34;kernel-compilation-and-preparing-sd-card&#34;&gt;Kernel compilation and preparing SD card&lt;/h1&gt;

&lt;h2 id=&#34;install-dependencies&#34;&gt;Install dependencies&lt;/h2&gt;

&lt;p&gt;Install the necessary depdendencies (In my case I was running ubuntu). Mainly
you need the tools for crosscompiling the kernel, configure u-boot and partition
the SD card with a GPT partition table.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install u-boot-tools gcc-arm-linux-gnueabihf \
    binutils-arm-linux-gnueabihf cgpt device-tree-compiler
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;set-up-some-directories-and-download-arch-and-kernel-sources&#34;&gt;Set up some directories and download arch and kernel sources&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;TMP_PATH=$(pwd)/chromeos
mkdir -p $TMP_PATH
cd $TMP_PATH
mkdir -p root
mkdir -p mnt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download my custom files&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/Dhole/alarm_install.git .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download Arch rootfs tarball&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://archlinuxarm.org/os/ArchLinuxARM-chromebook-latest.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download kernel 3.8 with ChromeOS patches&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;KERNEL_BRANCH=&amp;quot;chromeos-3.8&amp;quot;
git clone https://chromium.googlesource.com/chromiumos/third_party/kernel.git \
    -b $KERNEL_BRANCH --depth 1 chromeos
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;build-the-kernel&#34;&gt;Build the kernel&lt;/h2&gt;

&lt;p&gt;Set up the config for the chromebook&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd $KERNEL_BRANCH
CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm make mrproper
./chromeos/scripts/prepareconfig chromeos-exynos5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure the kernel as needed (Alternativelly, download my custom .config). In
my case I enabled most of the cipher options to be able to use AES-XTS in LUKS.
Be sure to disable &amp;ldquo;Treat compiler warnings as errors&amp;rdquo; in menuconfig&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm make menuconfig
# or
cp ../files/.config .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compile the kernel&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm make uImage -j2
CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm make modules -j2
CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm make dtbs -j2

rm -rf ../lib/modules/
CROSS_COMPILE=arm-linux-gnueabihf- ARCH=arm INSTALL_MOD_PATH=$TMP_PATH \
    make modules_install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Take the kernel.its from my files and make a u-boot image&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# wget http://linux-exynos.org/dist/chromebook/snow/kernel.its \
#    -O arch/arm/boot/kernel.its
cp ../files/kernel.its arch/arm/boot/.
mkimage -f arch/arm/boot/kernel.its $TMP_PATH/vmlinux.uimg
cd $TMP_PATH
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;prepare-sd-card&#34;&gt;Prepare SD card&lt;/h2&gt;

&lt;p&gt;Set your SD card device&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DISK=/dev/sde
sudo umount $DISK*
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create a new disk label for GPT. Type y when prompted after running&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo parted $DISK mklabel gpt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Partition the SD card&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cgpt create -z $DISK 
sudo cgpt create $DISK 
sudo cgpt add -i 1 -t kernel -b 8192 -s 32768 -l U-Boot -S 1 -T 5 -P 10 $DISK 
sudo cgpt add -i 2 -t data -b 40960 -s 32768 -l Kernel $DISK
sudo cgpt add -i 12 -t data -b 73728 -s 32768 -l Script $DISK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create root partition&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PART_SIZE=$(cgpt show $DISK | egrep &#39;[0-9\ ]*Sec GPT table&#39; | awk &#39;{print $1}&#39;)
sudo cgpt add -i 3 -t data -b 106496 -s `expr $PART_SIZE - 106496` -l Root $DISK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tell the system to refresh what it knows about the disk partitions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;partprobe $DISK
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Format partitions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mkfs.ext2 &amp;quot;${DISK}2&amp;quot;
sudo mkfs.ext4 &amp;quot;${DISK}3&amp;quot;
sudo mkfs.vfat -F 16 &amp;quot;${DISK}12&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;install-nv-uboot-fb&#34;&gt;Install nv_uboot_fb&lt;/h2&gt;

&lt;p&gt;Download and install the nv_uboot bootloader with framebuffer support in the SD&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget -O - http://commondatastorage.googleapis.com/chromeos-localmirror/distfiles/nv_uboot-snow-simplefb.kpart.bz2 \
    | bunzip2 &amp;gt; nv_uboot.kpart
sudo dd if=nv_uboot.kpart of=&amp;quot;${DISK}1&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;prepare-the-rootfs-for-encryption&#34;&gt;Prepare the rootfs for encryption&lt;/h2&gt;

&lt;p&gt;Create key file. Store this file safely!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dd if=/dev/urandom of=rootfs.key bs=128 count=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create luks container with key file&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cryptsetup luksFormat &amp;quot;${DISK}3&amp;quot; rootfs.key -c aes-xts-plain64 -s 256 --hash sha512
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add password to luks container&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cryptsetup luksAddKey &amp;quot;${DISK}3&amp;quot; --key-file rootfs.key
sudo cryptsetup luksOpen &amp;quot;${DISK}3&amp;quot; alarm_rootfs -y --key-file rootfs.key
sudo mkfs.ext4 /dev/mapper/alarm_rootfs
sudo cryptsetup close alarm_rootfs
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;install-arch-linux-kernel-and-custom-files&#34;&gt;Install Arch Linux, kernel and custom files&lt;/h2&gt;

&lt;h3 id=&#34;mount-luks-and-boot-partition&#34;&gt;Mount LUKS and boot partition&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo cryptsetup luksOpen &amp;quot;${DISK}3&amp;quot; alarm_rootfs -y --key-file rootfs.key
sudo mount /dev/mapper/alarm_rootfs root
sudo mount &amp;quot;${DISK}2&amp;quot; mnt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Extract Arch Linux rootfs tarball&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;tar -xf ArchLinuxARM-chromebook-latest.tar.gz -C root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Copy the kernel to the kernel partition&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp vmlinux.uimg mnt
rm -rf root/usr/lib/modules/3.8.11/
cp -R lib root/usr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Copy custom mkinitcpio.conf (with crypt hook enabled)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp files/mkinitcpio.conf root/etc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install initramfs from my files&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp files/uInitrd.img mnt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, if you already have an Arch installation on your Chromebook you
can create the initramfs yourself. From your Chromebook run as root.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pacman -S mkinitcpio uboot-mkimage
cp /root/files/mkinitcpio.conf /etc/mkinitcpio.conf
mkinitcpio -g ~/uInitrd.img
mount /dev/mmcblk1p2 /boot
mkimage -A arm -T ramdisk -C none -n initramfs -d ~/uInitrd.img /boot/uInitrd.uimg
umount /boot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install custom u-boot script to boot with kernel+initramfs&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo mount &amp;quot;${DISK}12&amp;quot; mnt
mkdir -p mnt/u-boot
#wget http://archlinuxarm.org/os/exynos/boot.scr.uimg
mkimage -A arm -T script -C none -n &#39;Chromebook Boot Script&#39; \
    -d boot_custom2.scr boot.scr.uimg
cp boot.scr.uimg mnt/u-boot
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Optional&lt;/em&gt;: Copy custom files for post-installation&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp files/arch_mkinitcpio.sh root/root/
cp files/postinstall.sh root/root/   
cp files/arch/private/mlan0-wrt54gl root/etc/netctl/
mkdir -p root/root/files/
cp -R files/arch/* root/root/files/
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;umount-luks-and-boot-partition&#34;&gt;Umount LUKS and boot partition&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;sudo umount mnt
sudo umount root
sudo cryptsetup close alarm_rootfs
sync
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;arch-configuration&#34;&gt;Arch configuration&lt;/h1&gt;

&lt;p&gt;Boot your Chromebook and press Ctrl-U to boot from external drive. After you
see U-Boot start, press any kay to interrupt the boot process and type the
following in the prompt to reset the environment and save it to flash&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;env default -f
saveenv
reset
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can now boot the Chromebook into Arch and configure the system. Login as
root to continue.&lt;/p&gt;

&lt;p&gt;Configure and connect wifi&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wifi-menu mlan0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure locale, timezone and hostname&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;MYHOSTNAME=&amp;quot;alarm&amp;quot;
USERNAME=&amp;quot;dhole&amp;quot;

locale-gen
localectl set-locale LANG=en_US.UTF-8
timedatectl set-timezone Europe/Madrid
hostnamectl set-hostname $MYHOSTNAME
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add user&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pacman -Sy
pacman -S sudo
useradd -m -G users -s /bin/bash $USERNAME
passwd $USERNAME
visudo # uncomment the wheel group
usermod -a -G wheel $USERNAME
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;post-install&#34;&gt;Post install&lt;/h1&gt;

&lt;p&gt;At this point you should have a bootable full disk encryption Arch Install.
In the following lines I will detail the post installation steps I follow to
cover my needs in the laptop. Run all the following commands as root.&lt;/p&gt;

&lt;p&gt;Install some packages (tune this to your needs)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pacman -S mesa-libgl xorg-server xorg-xinit xorg-server-utils mesa xf86-video-fbdev \
xf86-input-synaptics unzip dbus lightdm lightdm-gtk-greeter gnome-icon-theme xfce4 \
firefox midori gnome-keyring wget vim ttf-dejavu ttf-ubuntu-font-family htop strace \
lsof i3 xscreensaver git conky dmenu profont dina-font tamsyn-font alsa-utils ntp \
pm-utils p7zip xarchiver unrar zip python-pip tmux mpv mc make tmux iputils rtorrent \
youtube-dl macchanger tree acpid pulseaudio pulseaudio-alsa mupdf clang file gvim \
mosh nmap rxvt-unicode thunar adduser rsyslog wicd chromium xf86-video-armsoc-chromium \
i3lock
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Disable clearing of boot messages&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /etc/systemd/system/getty@tty1.service.d/
echo -e &amp;quot;[Service]\nTTYVTDisallocate=no&amp;quot; &amp;gt; /etc/systemd/system/getty@tty1.service.d/noclear.conf
mkdir -p /etc/ld.conf/
echo &amp;quot;/usr/local/lib&amp;quot; &amp;gt;&amp;gt; /etc/ld.conf.d/local.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install fonts &lt;a href=&#34;http://linuxfonts.narod.ru/&#34;&gt;http://linuxfonts.narod.ru/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/fonts.conf /etc/fonts/conf.d/99-my-fonts.conf
cd /usr/share
7z e /root/files/fonts.7z
cd /root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enable suspend and xscreen lock on lid close:
&lt;a href=&#34;https://blog.omgmog.net/post/making-suspend-on-lid-close-work-with-arch-linux-on-the-hp-chromebook-11/&#34;&gt;https://blog.omgmog.net/post/making-suspend-on-lid-close-work-with-arch-linux-on-the-hp-chromebook-11/&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/handler.sh /etc/acpi/handler.sh
systemctl enable acpid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install custom touchpad, keyboard, evdev&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/xorg.conf.d/* /etc/X11/xorg.conf.d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enable lightdm&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl enable lightdm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set default brightness on power up and script to change it&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/brightness.conf /etc/tmpfiles.d/brightness.conf
cp /root/files/chbr /usr/local/bin/chbr
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure pulseaudio&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &amp;quot;load-module module-alsa-sink device=sysdefault&amp;quot; &amp;gt;&amp;gt; /etc/pulse/default.pa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enable rsyslog&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;systemctl enable rsyslog.service
systemctl start rsyslog.service
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Change MAC at every connection&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/mac_change /etc/wicd/scripts/preconnect/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fix wicd-curses:
&lt;a href=&#34;https://github.com/voidlinux/void-packages/commit/220de599ad3ecba14423289209a3e4e031037edf&#34;&gt;https://github.com/voidlinux/void-packages/commit/220de599ad3ecba14423289209a3e4e031037edf&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/netentry_curses.py /usr/share/wicd/curses/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Enable eduroam for wicd:
&lt;a href=&#34;http://chakraos.org/wiki/index.php?title=Wicd#Making_eduroam_work_with_wicd&#34;&gt;http://chakraos.org/wiki/index.php?title=Wicd#Making_eduroam_work_with_wicd&lt;/a&gt;
This setup is working for eduroam at Universitat Politècnica de Catalunya&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/ttls-80211 /etc/wicd/encryption/templates/
cd /etc/wicd/encryption/templates
echo ttls-80211 &amp;gt;&amp;gt; active
cd /root
mkdir -p /etc/ca-certificates/custom/
cp /root/files/AddTrustExternalCARoot.crt /etc/ca-certificates/custom/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Chromium defaults&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/chromium_default /etc/chromium/default
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install wicd saved networks (This is only for my personal usage, this config
is not in github)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp /root/files/private/wireless-settings.conf /etc/wicd/
systemctl enable wicd
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Install my custom configuration for the user from my dot_files github repo. This
contains my vim settings, i3 window manager configuration for chromebook,
bashrc, tmux.conf, etc. Login as your user to run the following commands.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd ~
mkdir -p github
cd github
git clone https://github.com/Dhole/dot_files.git
cd dot_files
cp -R .* ~
cp ALARM/.* ~
sh vim_setup.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;todo&#34;&gt;TODO&lt;/h1&gt;

&lt;p&gt;There are only two things which I find missing from my installation.&lt;/p&gt;

&lt;p&gt;One is fixing an annoying issue with suspend: my chromebook wakes from sleep
after 10 minutes or so when the lid is closed. I&amp;rsquo;ve tryed using both suspend from
systemctl and from pm-suspend. I think this may be related to the kernel 3.8,
since I didn&amp;rsquo;t have this issue on 3.4 (well, not really, my laptop would wake
up some times, but it was not usual).&lt;/p&gt;

&lt;p&gt;The other one is doing the installation on the internal eMMC. Unfortunately the
SD card slot in the chromebook is placed very close to the end of the board, so
half of the SD card sticks out; it doesn&amp;rsquo;t look nice and I fear for the SD card
getting stuck somewhere when moving my chromebook around.&lt;/p&gt;

&lt;h1 id=&#34;resources&#34;&gt;Resources&lt;/h1&gt;

&lt;p&gt;The installation process of Arch Linux on the Samsung Chromebook is taken from
[1], [2] and [3]. The procedure to compile and install of kernel 3.8 is taken from
[0]. The instructions to boot with initramfs to enable full disk encryotion
are taken from [4], and a reference for doing an install with full disk encryption
can be found at [5].&lt;/p&gt;

&lt;p&gt;[0] &lt;a href=&#34;https://elatov.github.io/2014/11/install-chromeos-kernel-38-on-samsung-chromebook/&#34;&gt;https://elatov.github.io/2014/11/install-chromeos-kernel-38-on-samsung-chromebook/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[1] &lt;a href=&#34;https://elatov.github.io/2014/02/install-arch-linux-samsung-chromebook/&#34;&gt;https://elatov.github.io/2014/02/install-arch-linux-samsung-chromebook/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2] &lt;a href=&#34;http://archlinuxarm.org/platforms/armv7/samsung/samsung-chromebook&#34;&gt;http://archlinuxarm.org/platforms/armv7/samsung/samsung-chromebook&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[3] &lt;a href=&#34;http://linux-exynos.org/wiki/Samsung_Chromebook_XE303C12/Installing_Linux&#34;&gt;http://linux-exynos.org/wiki/Samsung_Chromebook_XE303C12/Installing_Linux&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[4] &lt;a href=&#34;http://archlinuxarm.org/forum/viewtopic.php?f=47&amp;amp;t=7071&#34;&gt;http://archlinuxarm.org/forum/viewtopic.php?f=47&amp;amp;t=7071&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[5] &lt;a href=&#34;https://dvikan.no/the-smallest-archlinux-install-guide&#34;&gt;https://dvikan.no/the-smallest-archlinux-install-guide&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Booting the GameBoy with a custom logo</title>
      <link>https://dhole.github.io/post/gameboy_custom_logo/</link>
      <pubDate>Thu, 25 Dec 2014 01:35:42 +0100</pubDate>
      
      <guid>https://dhole.github.io/post/gameboy_custom_logo/</guid>
      <description>

&lt;p&gt;With the cartridge emulator implemented on an STM32F4 we can do some cool stuff.
For example, we can make the GameBoy boot with our own custom logo!&lt;/p&gt;

&lt;h1 id=&#34;bootstrap-rom&#34;&gt;Bootstrap ROM&lt;/h1&gt;

&lt;p&gt;When the GameBoy boots, an intenral Bootstrap ROM is mapped to the beginning of the
memory and execution begins. This bios is in charge of initializing the hardware
as well as scrolling the Nintendo logo and checking that the cartridge i valid.
The logo shown on screen is actually read from the cartridge; that&amp;rsquo;s the reason
why a black rectangle appears when no cartridge is inserted, or garbage appears
when the cartridge pins fail. If the Nintendo logo doesn&amp;rsquo;t match the copy stored
in the bios, the GameBoy locks itself. But there is a trick we can do! The
GameBoy reads the logo from the cartridge two times, the first one to draw it
on screen and the second one to check if it&amp;rsquo;s valid. We can thus send first a
custom logo and later the original one in order to let the GameBoy boot properly.&lt;/p&gt;

&lt;p&gt;More on the GameBoy Bootstrap ROM can be read at &lt;a href=&#34;http://gbdev.gg8.se/wiki/articles/Gameboy_Bootstrap_ROM&#34;&gt;GBdevWiki&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;code&#34;&gt;Code&lt;/h1&gt;

&lt;p&gt;In order to achieve this we can modify the read function of our cartridge emulator
to the following:&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;no_show_logo&lt;/code&gt; flag is false at boot, and allows the first logo read (stored
in the ROM from 0x104 to 0x133) to be done on a custom array. Once the last byte
has been read, the flag is set to true so that the following reads are performed
to the real ROM.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/Dhole/a097cee60b990f65d869.js&#34;&gt;&lt;/script&gt;


&lt;h2 id=&#34;custom-logo-creation&#34;&gt;Custom logo creation&lt;/h2&gt;

&lt;p&gt;In order to create custom logos I wrote two python scripts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/draw_logo.py&#34;&gt;draw_logo.py&lt;/a&gt;: Draws a logo on a window&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/make_logo.py&#34;&gt;make_logo.py&lt;/a&gt;: Converts a png logo image into a binary file to be used as a boot logo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The logo is stored in inside the cartridge with a binary representation:
Set bits represent a black pixel and unset bits represent a white pixel. The logo is
stored in blocks of 4x4, first filling the top part and later filling the bottom part.
The way the pixels are stored can be understood better by looking at &lt;code&gt;draw_logo.py&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;make_logo.py&lt;/code&gt; allows you to convert a 48x8 pixel black and white png image to a
binary logo to be used by the cart emulator&lt;/p&gt;

&lt;h1 id=&#34;results&#34;&gt;Results&lt;/h1&gt;

&lt;p&gt;I have drawn the following logo to be used at boot:&lt;/p&gt;


&lt;figure &gt;
    
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/dhole_logo.png&#34; alt=&#34;Custom logo featuring my nickname and a cute Dhole&#34; /&gt;
    
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Custom logo featuring my nickname and a cute Dhole
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;In the following videos the GameBoy booting with the custom logo can be seen:&lt;/p&gt;

&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;https://www.youtube.com/embed/aVxJXK9QvPk&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Booting with the custom logo, running Dr Mario.&lt;/p&gt;

&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;https://www.youtube.com/embed/OPYkzv217P4&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Booting with the custom logo, running the demo Skinke by Jumalauta.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Emulating a GameBoy Cartridge with an STM32F4. Part 2</title>
      <link>https://dhole.github.io/post/gameboy_cartridge_emu_2/</link>
      <pubDate>Wed, 24 Dec 2014 19:46:07 +0100</pubDate>
      
      <guid>https://dhole.github.io/post/gameboy_cartridge_emu_2/</guid>
      <description>

&lt;p&gt;This post is a continuation of &lt;a href=&#34;https://dhole.github.io/post/gameboy_cartridge_emu_1&#34;&gt;Emulating a GameBoy Cartridge with an STM32F4. Part 1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We have analyzed the memory bus of the GameBoy in order to obtain the timing
information of the different signals involved in the read and write operations
happening on the cartridge. We will now proceed to develop a system to emulate
the behaviour of the cartridge with the STM32F4.&lt;/p&gt;

&lt;h2 id=&#34;about-voltage-levels&#34;&gt;About voltage levels&lt;/h2&gt;

&lt;p&gt;As we noticed in the previous post, the GameBoy works at 5V whereas the STM32F4
works at 3.3V. We saw that most of the GPIOs of the STM32F4 are 5V tolerant, but
they still output 3.3V, so we need to make sure that the GameBoy will detect the
high levels properly. Luckily for us, the GameBoy works at TTL level:
&lt;a href=&#34;http://friedtj.free.fr/gb_eng.pdf&#34;&gt;source&lt;/a&gt;. This means that a 3.3V signal will
be read as a logic 1 by the GameBoy.&lt;/p&gt;

&lt;h1 id=&#34;setup&#34;&gt;Setup&lt;/h1&gt;

&lt;p&gt;We will use a similar setup here, although now we are going to connect all the
cartridge pins to the STM32F4 so that we can read/write the signals. We have
plenty of GPIOs on the STM32F4-Discovery, we just need to make sure we use the
5V compatible ones. I used the following setup:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CLK -&amp;gt; PC0&lt;/li&gt;
&lt;li&gt;RD -&amp;gt; PC1&lt;/li&gt;
&lt;li&gt;WR -&amp;gt; PC2&lt;/li&gt;
&lt;li&gt;DATA{0..7} -&amp;gt; PE{8..15}&lt;/li&gt;
&lt;li&gt;ADDR{0..15} -&amp;gt; PD{0..15}&lt;/li&gt;
&lt;/ul&gt;


&lt;figure &gt;
    
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_setup.jpg&#34; alt=&#34;My setup with the GameBoy connected to the STM32F4-Discovery&#34; /&gt;
    
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        My setup with the GameBoy connected to the STM32F4-Discovery
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;h1 id=&#34;coding&#34;&gt;Coding&lt;/h1&gt;

&lt;p&gt;The code of this project can be found in my github page under an open source
license: &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart&#34;&gt;github.com/Dhole&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;initialization&#34;&gt;Initialization&lt;/h2&gt;

&lt;p&gt;The initialization code can be found in &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/main.c&#34;&gt;main.c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The first thing to do is to configure the GPIOs of the board. All the GPIOs are
configured as input, push pull mode (will be used when we set the DATA GPIO pins
to output) with pull down resistor (I believe pull down resistor is a good choice
to avoid current drain from the GameBoy(5V) to the STM32F4(3.3V)). The bus for
the GPIOs is configured at 100MHz (maximum frequency available).&lt;/p&gt;

&lt;p&gt;This functions can be found in &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/main.c&#34;&gt;main.c&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void config_gpio_data();
void config_gpio_addr();
void config_gpio_sig();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Secondly, we will configure the CLK to act as a trigger on rise. To do this we
enable an interrupt for the GPIO we connected the CLK to that will execute a
handler for every level rise. In &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/main.c&#34;&gt;main.c&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;void config_PC0_int(void);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;read-write-handler&#34;&gt;Read/Write handler&lt;/h2&gt;

&lt;p&gt;The read/write handler can be found in &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/stm32f4xx_it.c&#34;&gt;stm32f4xx_it.c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The interrupt handler will be executed every time the CLK level goes high (rise).
It&amp;rsquo;s important to notice that there is some delay between the rise of CLK and
the execution of the handler. This may be because the GPIOs are peripherials that
communicate with the CPU through a bus clocked at 100MHz and also because the
interrupt is generated from a peripherial, and thus takes some time to be
processed by the CPU. This can be observed if you try to write a program that
toggles the output of a GPIO unpon rise of the CLK, and then monitor both signals
in an oscilloscope.&lt;/p&gt;

&lt;p&gt;The handler must wait some time until the addresses are ready in the bus. To
perform fine grained waits I use the NOP operation, which wastes one CPU cycle.
After reading the GPIOs connected to the addresses, we check if the operation is
a read or a write by reading the values of the GPIOs connected to RD and WR.&lt;/p&gt;

&lt;p&gt;In case of write, we must wait further until the data is available in the bus,
then we can read the GPIOs and perform the write.&lt;/p&gt;

&lt;p&gt;In case of the read, we must first set the GPIOs associated with the data as
output (we configured them to be input). Then we can output the data corresponding
to the address, and wait some cycles so that the GameBoy can read the contents.
After this, the GPIOs for data are configured back to input mode (default state).
Leaving the GPIOs of the data in input state as default is necessary because
sometimes the GameBoy will perfom write operations to internal RAM and having
these GPIOs as output will corrut the data sent by the GameBoy.&lt;/p&gt;

&lt;p&gt;If you take a look at IRQHandler examples for the STM32F4 you will notice some
differences. The library functions normally used in a handler have been replaced
by the specific operation. This is because calling a function consumes some
cycles (due to the context change) and also they contain asserts to verify the
input, which consumes more cycles. We are short in cycles here, so we try to avoid
all this.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/Dhole/ed6cde3ec6b6574e080f.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;To perform an arbitrary number of NOP operations, I used a macro I found on
&lt;a href=&#34;https://stackoverflow.com/questions/8551418/c-preprocessor-macro-for-returning-a-string-repeated-a-certain-number-of-times&#34;&gt;stackoverflow&lt;/a&gt;. The C preprocessor doesn&amp;rsquo;t
allow to repeat an operations a number of times.&lt;/p&gt;

&lt;p&gt;Finding the proper number of NOP operations at each stage of the operation has
been the most difficult part of the implementation because it needs to be done
with trial and error. Adding a new case to an if statement changes the number of
cycles of the handler, so the number of NOPs may need to be readjusted. More over,
the compilation optimizations are quite unpredictable regarding how many op codes
are used for the code (and thus, how many cycles are spent on the execution), so
a small change can lead to a malfunctioning system.&lt;/p&gt;

&lt;h2 id=&#34;mbc1-implementation&#34;&gt;MBC1 implementation&lt;/h2&gt;

&lt;p&gt;The read and write functions implementing the behaviour of the MBC1 can be found
in &lt;a href=&#34;https://github.com/Dhole/stm32f_GBCart/blob/master/stm32f4xx_it.c&#34;&gt;stm32f4xx_it.c&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A detailed explanation of the functionality of the different Memory Block
Controllers can be found in the &lt;a href=&#34;http://gbdev.gg8.se/wiki/articles/Memory_Bank_Controllers&#34;&gt;GBdevWiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For the read operation, three regions can be accessed. The first one maps to
the first 16KB of the ROM. The second one to the selectable ROM bank. The third
one to the selectable RAM bank, if any:&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/Dhole/dc998ea525a208987a69.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;For the write operation, it can happen that it accesses the RAM region, where
it performs a proper read, or it can access three other regions. The first one is
used to select the lower bits of the ROM bank. The second one is used to select the
RAM bank or the upper bits of the ROM bank, depending on the state of a ROM/RAM
mode flag. The third one is to enable or disable the ROM/RAM mode flag. There is also
an initial region to enable or disable the RAM, used by the cartridges to protect
the RAM agains data corruption, but it&amp;rsquo;s not needed here.&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/Dhole/7417a4095600fe31b1dd.js&#34;&gt;&lt;/script&gt;


&lt;h3 id=&#34;rom-and-ram&#34;&gt;ROM and RAM&lt;/h3&gt;

&lt;p&gt;In order to allow the program to access to the contents of a ROM, I used the
unix &lt;code&gt;xxd&lt;/code&gt; tool to convert the binary file into a C header file containing an array
with the file contents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp Tetris.gb rom.gb
xxd -i rom.gb | sed &#39;s/unsigned/unsigned const/g&#39; &amp;gt; tetris_rom.h
rm rom.gb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The contents of &lt;em&gt;tetris_rom.h&lt;/em&gt; will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unsigned const char rom_gb[] = {
  0xc3, 0x0c, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0xc3, 0x0c, 0x02, 0xff,
  ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For games that use RAM, an array must be allocated on the SMT32F4. For this
purpose, an array of 32KB (Maximum RAM size for MBC1) will be declared:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;uint8_t ram[0x8000]; // 32K
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice that the saved game will only remain as long as the STM32F4 is not powered
off.&lt;/p&gt;

&lt;h1 id=&#34;results&#34;&gt;Results&lt;/h1&gt;

&lt;h2 id=&#34;photos&#34;&gt;Photos&lt;/h2&gt;


&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_zelda.jpg&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_zelda.jpg&#34; alt=&#34;The Legend of Zelda. MBC1 game. Showing the cart RAM usage (The name, EDU, is saved in the cartridge RAM)&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        The Legend of Zelda. MBC1 game. Showing the cart RAM usage (The name, EDU, is saved in the cartridge RAM)
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;




&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_drmario.jpg&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_drmario.jpg&#34; alt=&#34;Dr. Mario. ROM Only game&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Dr. Mario. ROM Only game
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;h2 id=&#34;videos&#34;&gt;Videos&lt;/h2&gt;

&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;https://www.youtube.com/embed/M7dIPUz1igs&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Running The Legend of Zelda, - Link&amp;rsquo;s Awakening, showing that the
cartridge RAM is working.&lt;/p&gt;

&lt;div class=&#34;embed video-player&#34;&gt;
&lt;iframe class=&#34;youtube-player&#34; type=&#34;text/html&#34; width=&#34;640&#34; height=&#34;385&#34; src=&#34;https://www.youtube.com/embed/_hMnb0bsdyU&#34; allowfullscreen frameborder=&#34;0&#34;&gt;
&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Running the demo 20y by Snorpung.&lt;/p&gt;

&lt;h1 id=&#34;conclusions&#34;&gt;Conclusions&lt;/h1&gt;

&lt;p&gt;Being able to emulate a full cartridge with its RAM and memory banking with an
ARM development board was really awesome. I wasn&amp;rsquo;t sure this was doable, and
hadn&amp;rsquo;t seen anything similar. I don&amp;rsquo;t own any gameboy flashcarts, so being able
to run code on the gameboy from something I built was extremely satisfactory. I
enjoy watching works of demoscene, and with this project I was able to try out
many amazing demos on the GameBoy.&lt;/p&gt;

&lt;p&gt;On the technical side, this project took me a few days of fine tunning and
adding capabilites. This was my first time developing on the STM32F4 so I also
spent a few days documenting myself. The biggest issue I have found is the
timing constraints. Adding cases to if statements, changin the order of some
operations, modifying code&amp;hellip; all this modifies the timing of the instructions
generated by the compiler, sometimes not very intuitively due to strong compiler
optimizations. I spent some hours of trial and error checking that all the
operations worked fine. Also you may have noticed that all the code runs inside
the interruption handler. And this handler is triggered at 1MHz! This gives a
tight margin of operation. If the operations inside the interrupt takes too long,
they will mask the next interruption and a following read/write operation (in
case there was one) will be missed, probably crashing the GameBoy. Care must be
taken to not exceed this timing constraint.&lt;/p&gt;

&lt;p&gt;In the following post I will write about adding a custom boot logo to the
cartridge emulator. Stay tunned!&lt;/p&gt;

&lt;p&gt;Continuation: &lt;a href=&#34;https://dhole.github.io/post/gameboy_custom_logo&#34;&gt;Booting the GameBoy with a custom logo&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Emulating a GameBoy Cartridge with an STM32F4. Part 1</title>
      <link>https://dhole.github.io/post/gameboy_cartridge_emu_1/</link>
      <pubDate>Wed, 24 Dec 2014 03:33:57 +0100</pubDate>
      
      <guid>https://dhole.github.io/post/gameboy_cartridge_emu_1/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;The following project consists on emulating the functionality of a GameBoy
cartridge with the development board STM32F4. The system is fully functional
and is able to emulate real cartridges (as well as homebrew games) of the type
ROM Only and MBC1 (Memory Block Controller 1). In this post I will explain
how I managed to achieve this.&lt;/p&gt;

&lt;h1 id=&#34;motivation&#34;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;Current flashcart systems commonly use a design consisting on a FPGA or CPLD
controlling the logic of the emulated cartridge (memory banking, RAM access,
etc.), a media storage (flash chip or SD card) and an SDRAM chip.&lt;/p&gt;

&lt;p&gt;The way this flashcarts work is that upon booting the console, they present a
small program that list the ROMs available in the media storage. The user selects
a game and the FPGA copies it from the media storage to the SDRAM to allow
fast access. Once the ROM has been copied, the FPGA acts as a gateway mapping
the contents of the SDRAM to the original cartridge mappings.&lt;/p&gt;

&lt;p&gt;Since the GameBoy cartridges use small ROM chips for which one can find
compatible FLASH chips in the market, it is a viable alternative to the FPGA
to take an original cartridge with a MBC5 and swap the original ROM chip with
a compatible FLASH memory. A cartridge with MBC5 is often selected because with
it, games with ROM Only and games using MBC1 can also be run (There is
compatibility). With this setup, the user is able to reprogram the FLASH many
times with different games and play them on the GameBoy.&lt;/p&gt;

&lt;p&gt;This procedure is detailed here:
&lt;a href=&#34;http://www.digital-circuitry.com/DOC/NINTENDO/GAMEBOY/DIY%20Nintendo%20GAMEBOY%20Classic%20Flash%20Cartridge.pdf&#34;&gt;DIY Nintendo GAMEBOY Classic Flash Cartridge&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The FPGA system seems to allow much more freedom but it also involves more work:
the MBC5 (or the supported Memory Block Controllers) must be implemented in
hardware, an interface to access the media storage must be designed, the circuit
must be designed too with all the components (FPGA/CPLD, FLASH/SD Reader, SDRAM,
&amp;hellip;).&lt;/p&gt;

&lt;p&gt;An alternative to this one can think of would be to use a microcontroller
instead, interfacing the cartridge pins through the GPIO. This design can have
many complications since the timings to perform a read / write operation are
quite tight. The microcontroller should be fast enough to perform this operations
at the bus speed. When adding the functionality of the Memory Block controller
the timings could be hard to achieve.
&lt;a href=&#34;https://www.insidegadgets.com/2011/04/23/emulating-the-nintendo-logo-on-the-gameboy/&#34;&gt;Alex from Inside Gadgets&lt;/a&gt;
attempted to
achieve this using an Arduino. The low frequency of the Arduino made this project
infeasible, although Alex was able to achive the emulation of the Nintendo logo,
due to the fact that when the gameboy boots, the first read of the Nintendo logo
from the cartridge is timming predictable and not too fast:&lt;/p&gt;

&lt;p&gt;My aim was to try to implement a cartridge emulator using a faster microcontroller.&lt;/p&gt;

&lt;h1 id=&#34;the-hardware&#34;&gt;The hardware&lt;/h1&gt;

&lt;p&gt;For this project I choosed the STM32F4 Discovery. This development board features
an ARM Cortex-M4 which can run at 168MHz, with 1 MB Flash, 192 KB RAM and more than
70 GPIO. The GPIO are accessed through a peripherials bus that can run at 100MHz.
I also considered other boards such as the Teensy 3.1 but I ended up choosing
the STM32F4 because it had more Flash and RAM and because it was unexpensive (14€).&lt;/p&gt;

&lt;p&gt;On the other side, the GameBoy CPU runs at 4MHz. The comercial cartridges have
up to 512 KB of ROM and 128 KB of RAM, although the MBC5 is capable of handling
bigger ROMs. Many cartridges have a MBC (Memory Block Controler) such as the MBC5
or the MBC1. This controller allows the catridge to handle ROMs that don&amp;rsquo;t fit
into the GameBoy memory area reserved for the cartridge ROM by means of bank
selection. This selections are performed by writting into specific areas of the
memory map reserved for the ROM (So that the MBC can handle them).&lt;/p&gt;

&lt;p&gt;A list of characteristics of the comercial cartridges can be found here:
&lt;a href=&#34;http://www.devrs.com/gb/files/gbmbcsiz.txt&#34;&gt;GB Cart List&lt;/a&gt;
It is important to notice that the GameBoy works at 5V whereas the STM32F4 works
at 3.3V. Connecting 5V signals to the GPIOs of a 3.3 microcontroller can be
dangerous and damage the GPIO peripherials. Luckily the STM32F4-Discovery has
5V tolerance for most of the pins. To see which ones you can check the
documentation.&lt;/p&gt;

&lt;p&gt;With these characteristics it seems this project can be doable. If we consider
that the gameboy will perform at most a read / write per CPU cycle (We will later
see that this is not the case), we are left with 42 cycles of our dev board to handle
the operation. Taking into account that the GPIO bus is clocked at 100MHz, there
will be some delay which will leave us fewer cycles.&lt;/p&gt;

&lt;h1 id=&#34;analyzing-the-bus&#34;&gt;Analyzing the bus&lt;/h1&gt;

&lt;p&gt;In order to get an idea of how the bus used by the GameBoy to access the
cartridge works I decided to perform some captures using a Logic Analyzer. Since
I don&amp;rsquo;t have any hardware logic analyzer, I used a an awesome project
which consists of an implementation of a logic analyzer for the STM32F4, which
uses the SUMP protocol to interface with the PC (SUMP is a standard protocol for
hardware logic analyzers to interface with the client side). The logicdiscovery
allows to sample up to 20MHz on 16 channels, with up to 24k samples:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://code.google.com/p/logicdiscovery/&#34;&gt;logicdiscovery&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The client used is the Logic Sniffer, an open source Java client compatible with
the SUMP protocol:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.lxtreme.nl/ols/&#34;&gt;Logic Sniffer&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In order to analyze the bus while the GameBoy was performing reads and writes to
the cartridge, I soldered an FDD ribbon to the main board of the GameBoy,
intercepting the cartridge pins as follows:&lt;/p&gt;


&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_ribbon_1.jpg&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/gb_ribbon_1.jpg&#34; alt=&#34;Back of the GameBoy PCB with the cartridge pins soldered to a FDD ribbon.&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Back of the GameBoy PCB with the cartridge pins soldered to a FDD ribbon.
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;Since only 16 channels are available for the logicdiscovery I decided to monitor
the CLK, RD, WR, CS, DATA {0-4} and ADDR {0-8}. (That is, the lower 4 bits of
the data and the lower 8 bits of the address). With this we should be able to
get information about the timings of the different operations.&lt;/p&gt;

&lt;p&gt;The GameBoy cartridge pinout is well known, so it&amp;rsquo;s easy to figure out what every
pin on the PCB of the GameBoy does from a pinout picture:&lt;/p&gt;


&lt;figure &gt;
    
    
        &lt;img src=&#34;https://www.insidegadgets.com/wp-content/uploads/2011/03/IMG_1994.jpg&#34; alt=&#34;GameBoy cartridge pinout. Image from www.insidegadgets.com&#34; /&gt;
    
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        GameBoy cartridge pinout. Image from www.insidegadgets.com
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;

&lt;p&gt;Upon analyzing the bus with the BATMAN game (ROM Only cartridge), the following is obtained:&lt;/p&gt;


&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_overview.png&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_overview.png&#34; alt=&#34;Logic capture overview&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Logic capture overview
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;The first thing I noticed is that the CLK is at 1MHz, this is good news for us:
we have more cycles for each operation. One oddity I found with the capture is
that we can see that the WR goes low a few times (WR is active on low). The
BATMAN cartridge doesn&amp;rsquo;t have RAM nor Memory Block Controller, so it doesn&amp;rsquo;t make
sense to write into it. Since we only have half of the adressess, we can&amp;rsquo;t say
for certain where the data is being written, but my guess is that we are seeing
writes being done to the internal GameBoy RAM.&lt;/p&gt;

&lt;p&gt;We can take a closer look to a read and a write and analyze what&amp;rsquo;s happening and
when. This information will give us an idea on when should we perform the reading
of the adresses for a write/read operation, and when to output the data on a
read operation.&lt;/p&gt;

&lt;p&gt;Notice that we have a 20MHz sampling rate, this means that a sample is being
taken every 50 ns, leading to an error of +/- 25 ns.&lt;/p&gt;


&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_read_timings.png&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_read_timings.png&#34; alt=&#34;Read timings&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Read timings
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;




&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_write_timings.png&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_write_timings.png&#34; alt=&#34;Write timings&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        Write timings
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;We can see that for a read operation, the GameBoy leaves WR and CS unactivate
(high) and the RD active (low). This is the default. The GameBoy sets the
address 150ns after the CLK rise, and the data is available in the bus
(coming from the cartridge) 200 ns later. We can&amp;rsquo;t say when the GameBoy reads
the data, but a guess would be around the CLK fall.&lt;/p&gt;

&lt;p&gt;For the write operation, the RD is set to unactive at the same time the address
and the data is set in the bus (150 ns after CLK rise). 100 ns later the CS is
activated. At the CLK fall, the WR is activated, allowing the cartridge to perform
the write for 300 ns. On the next cycle, we can see that RD and CS are reset to
the default state (low and high, active and unactive respectively). Notice that
the CS (Chip Select) is not strictly needed, although it seems to be used only
when accessing RAM (this is not clear).&lt;/p&gt;

&lt;p&gt;The writing timing analysis are sound with the analysis found in the unnoficial
&lt;a href=&#34;http://marc.rawer.de/Gameboy/Docs/GBCPUman.pdf&#34;&gt;GameBoy CPU Manual&lt;/a&gt;:&lt;/p&gt;


&lt;figure &gt;
    
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/cpu_manual_timing.png&#34;&gt;
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/cpu_manual_timing_small.png&#34; alt=&#34;RAM timings, taken from the Game Boy CPU Manual. Click for detailed timings.&#34; /&gt;
    &lt;/a&gt;
    
    
    &lt;figcaption&gt;
        &lt;p&gt;
        RAM timings, taken from the Game Boy CPU Manual. Click for detailed timings.
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;Now that we know that the information seen in the bus is not only the communication
between the GameBoy and the cartridge but all the read/write operations of the
GameBoy to its memory map, we can understand the following capture, which shows
a DMA operation (The GameBoy has a DMA functionality to allow to fast copy contents
from RAM or ROM to the OAM (Object Atribute Memory), used by the screen to draw
sprites):&lt;/p&gt;


&lt;figure &gt;
    &lt;a href=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_DMA.png&#34;&gt;
    
        &lt;img src=&#34;https://dhole.github.io/media/gameboy_stm32f4/screen_dump_DMA.png&#34; alt=&#34;DMA in action&#34; /&gt;
    
    &lt;/a&gt;
    
    &lt;figcaption&gt;
        &lt;p&gt;
        DMA in action
        
            
        
        &lt;/p&gt; 
    &lt;/figcaption&gt;
    
&lt;/figure&gt;



&lt;p&gt;In the following post I will write about the implementation of the cartridge
emulator. Stay tunned!&lt;/p&gt;

&lt;p&gt;Continuation: &lt;a href=&#34;https://dhole.github.io/post/gameboy_cartridge_emu_2&#34;&gt;Emulating a GameBoy Cartridge with an STM32F4. Part 2&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Welcome</title>
      <link>https://dhole.github.io/post/first/</link>
      <pubDate>Sat, 08 Nov 2014 17:04:11 +0100</pubDate>
      
      <guid>https://dhole.github.io/post/first/</guid>
      <description>&lt;p&gt;I had been planning on creating a blog to write about the stuff I do on my free time for a while.
In this blog I plan to write about the projects I develop as well as talking about interesting things
I lean about technology, hardware, security, embedded systems, programming languages and more.&lt;/p&gt;

&lt;p&gt;My first thought was to use a WordPress hosted at wordpress.com, but I didn&amp;rsquo;t want the adds. I searched
on the net for alternatives and found out about the static website generators, which allow you to host
the content in a static web server such as your github personal page. Right now this blog is posted in
my server, but I may move it to github if there is some traffic.&lt;/p&gt;

&lt;p&gt;The platform choosen is &lt;a href=&#34;http://gohugo.io&#34;&gt;Hugo&lt;/a&gt;: a static website engine written in Go. There were
other options such as Jekyll and Oktopress, but I decided to try this one because I love Go and because
it&amp;rsquo;s really fast at generating the content.&lt;/p&gt;

&lt;p&gt;See you arround!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>